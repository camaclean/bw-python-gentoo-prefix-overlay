diff --git a/tensorflow/contrib/cmake/CMakeLists.txt b/tensorflow/contrib/cmake/CMakeLists.txt
index 83c82c7..ccf0985 100644
--- a/tensorflow/contrib/cmake/CMakeLists.txt
+++ b/tensorflow/contrib/cmake/CMakeLists.txt
@@ -19,6 +19,9 @@ cmake_policy(SET CMP0022 NEW)
 # Options
 option(tensorflow_VERBOSE "Enable for verbose output" OFF)
 option(tensorflow_ENABLE_GPU "Enable GPU support" OFF)
+option(tensorflow_CUDA_30 "Build for CUDA 3.0 compute capability" ON)
+option(tensorflow_CUDA_35 "Build for CUDA 3.5 compute capability" ON)
+option(tensorflow_CUDA_52 "Build for CUDA 5.2 compute capability" ON)
 option(tensorflow_ENABLE_SSL_SUPPORT "Enable boringssl support" OFF)
 option(tensorflow_ENABLE_GRPC_SUPPORT "Enable gRPC support" ON)
 option(tensorflow_ENABLE_HDFS_SUPPORT "Enable HDFS support" OFF)
@@ -32,6 +35,18 @@ option(tensorflow_BUILD_PYTHON_TESTS "Build python unit tests " OFF)
 option(tensorflow_BUILD_SHARED_LIB "Build TensorFlow as a shared library" OFF)
 option(tensorflow_OPTIMIZE_FOR_NATIVE_ARCH "Enable compiler optimizations for the native processor architecture (if available)" ON)
 option(tensorflow_WIN_CPU_SIMD_OPTIONS "Enables CPU SIMD instructions")
+option(tensorflow_ENABLE_MPI OFF)
+
+if(tensorflow_ENABLE_MPI)
+  find_package(MPI REQUIRED)
+endif()
+
+if(UNIX)
+  set(CMAKE_EXE_LINKER_FLAGS "$ENV{LDFLAGS}")
+  set(CMAKE_SHARED_LINKER_FLAGS "$ENV{LDFLAGS}")
+  set(CMAKE_C_FLAGS "${CMAKE_C_FLAGS} -O3")
+  set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -O3")
+endif()
 
 if (NOT WIN32)
   # Threads: defines CMAKE_THREAD_LIBS_INIT and adds -pthread compile option
@@ -202,53 +217,127 @@ if(UNIX)
   list(APPEND tensorflow_EXTERNAL_LIBRARIES ${CMAKE_THREAD_LIBS_INIT} ${CMAKE_DL_LIBS})
 endif()
 
+function(JOIN VALUES GLUE OUTPUT)
+  string (REGEX REPLACE "([^\\]|^);" "\\1${GLUE}" _TMP_STR "${VALUES}")
+  string (REGEX REPLACE "[\\](.)" "\\1" _TMP_STR "${_TMP_STR}") #fixes escaping
+  set (${OUTPUT} "${_TMP_STR}" PARENT_SCOPE)
+endfunction()
+
+if(NOT (tensorflow_CUDA_30 OR tensorflow_CUDA_35 OR tensorflow_CUDA_52))
+  set(tensorflow_ENABLE_GPU FALSE)
+endif()
+
 if (tensorflow_ENABLE_GPU)
+  find_package(CUDA 7.5 REQUIRED)
+
+  # by default we assume compute cabability 3.5 and 5.2. If you change this change it in
+  # CUDA_NVCC_FLAGS and cuda_config.h below
+  set(TF_EXTRA_CUDA_CAPABILITIES_30 "3.0")
+  set(TF_EXTRA_CUDA_CAPABILITIES_35 "3.5")
+  set(TF_EXTRA_CUDA_CAPABILITIES_52 "5.2")
+  set(CUDA_NVCC_FLAGS_30 "-gencode arch=compute_30,code=\"sm_30,compute_30\"")
+  set(CUDA_NVCC_FLAGS_35 "-gencode arch=compute_35,code=\"sm_35,compute_35\"")
+  set(CUDA_NVCC_FLAGS_52 "-gencode arch=compute_52,code=\"sm_30,compute_52\"")
+  set(TF_CUDA_CAPABILITIES_30 "CudaVersion(\"3.0\")")
+  set(TF_CUDA_CAPABILITIES_35 "CudaVersion(\"3.5\")")
+  set(TF_CUDA_CAPABILITIES_52 "CudaVersion(\"5.2\")")
+  if(tensorflow_CUDA_30)
+    set(CUDA_NVCC_FLAGS ${CUDA_NVCC_FLAGS} ${CUDA_NVCC_FLAGS_30})
+    set(TF_CUDA_CAPABILITIES_LIST ${TF_CUDA_CAPABILITIES_LIST} ${TF_CUDA_CAPABILITIES_30})
+    set(TF_EXTRA_CUDA_CAPABILITIES_LIST ${TF_EXTRA_CUDA_CAPABILITIES_LIST} ${TF_EXTRA_CUDA_CAPABILITIES_30})
+  endif()
+  if(tensorflow_CUDA_35)
+    set(CUDA_NVCC_FLAGS ${CUDA_NVCC_FLAGS} ${CUDA_NVCC_FLAGS_35})
+    set(TF_CUDA_CAPABILITIES_LIST ${TF_CUDA_CAPABILITIES_LIST} ${TF_CUDA_CAPABILITIES_35})
+    set(TF_EXTRA_CUDA_CAPABILITIES_LIST ${TF_EXTRA_CUDA_CAPABILITIES_LIST} ${TF_EXTRA_CUDA_CAPABILITIES_35})
+  endif()
+  if(tensorflow_CUDA_52)
+    set(CUDA_NVCC_FLAGS ${CUDA_NVCC_FLAGS} ${CUDA_NVCC_FLAGS_52})
+    set(TF_CUDA_CAPABILITIES_LIST ${TF_CUDA_CAPABILITIES_LIST} ${TF_CUDA_CAPABILITIES_52})
+    set(TF_EXTRA_CUDA_CAPABILITIES_LIST ${TF_EXTRA_CUDA_CAPABILITIES_LIST} ${TF_EXTRA_CUDA_CAPABILITIES_52})
+  endif()
+  join("${TF_CUDA_CAPABILITIES_LIST}" "," TF_CUDA_CAPABILITIES)
+  join("${TF_EXTRA_CUDA_CAPABILITIES_LIST}" "," TF_EXTRA_CUDA_CAPABILITIES)
+  
+  if(${CUDA_VERSION} STREQUAL "7.5")
+    if(WIN32)
+      set(TF_CUDA_VERSION "64_75")
+    else()
+      set(TF_CUDA_VERSION "7.5")
+    endif()
+  elseif(${CUDA_VERSION} STREQUAL "8.0")
+    if(WIN32)
+      set(TF_CUDA_VERSION "64_80")
+    else()
+      set(TF_CUDA_VERSION "8.0")
+    endif()
+  endif()
+  if(NOT CUDNN_VERSION)
+    set(CUDNN_VERSION "5")
+  endif(NOT CUDNN_VERSION)
+  if(WIN32)
+    set(TF_CUDNN_VERSION "64_${CUDNN_VERSION}")
+  else()
+    set(TF_CUDNN_VERSION "${CUDNN_VERSION}")
+  endif()
+
+  set(CUDA_NVCC_FLAGS ${CUDA_NVCC_FLAGS};--include-path ${PROJECT_BINARY_DIR}/$\{build_configuration\};--expt-relaxed-constexpr)
+  set(CUDA_NVCC_FLAGS ${CUDA_NVCC_FLAGS};-ftz=true)  # Flush denormals to zero
+  if(UNIX)
+    set(CMAKE_EXE_LINKER_FLAGS "${CMAKE_EXE_LINKER_FLAGS} -Wl,--rpath=${CUDA_TOOLKIT_TARGET_DIR}/lib64 -Wl,--rpath=${CUDA_TOOLKIT_TARGET_DIR}/extras/CUPTI/lib64")
+    set(CMAKE_SHARED_LINKER_FLAGS "${CMAKE_SHARED_LINKER_FLAGS} -Wl,--rpath=${CUDA_TOOLKIT_TARGET_DIR}/lib64 -Wl,--rpath=${CUDA_TOOLKIT_TARGET_DIR}/extras/CUPTI/lib64")
+    set(CUDA_NVCC_FLAGS ${CUDA_NVCC_FLAGS};-Xcompiler;-fPIC)
+  endif(UNIX)
+  set(CUDA_INCLUDE ${CUDA_TOOLKIT_TARGET_DIR} ${CUDA_TOOLKIT_TARGET_DIR}/extras/CUPTI/include)
+  include_directories(${CUDA_INCLUDE})
+  add_definitions(-DGOOGLE_CUDA=1 -DTF_EXTRA_CUDA_CAPABILITIES=${TF_EXTRA_CUDA_CAPABILITIES})
+
+  # add cudnn
   if (WIN32)
-    find_package(CUDA 8.0 REQUIRED)
-
-    # by default we assume compute cabability 3.5 and 5.2. If you change this change it in
-    # CUDA_NVCC_FLAGS and cuda_config.h below
-    set(CUDA_NVCC_FLAGS ${CUDA_NVCC_FLAGS};-gencode arch=compute_30,code=\"sm_30,compute_30\";-gencode arch=compute_35,code=\"sm_35,compute_35\";-gencode arch=compute_52,code=\"sm_52,compute_52\")
-    set(CUDA_NVCC_FLAGS ${CUDA_NVCC_FLAGS};--include-path ${PROJECT_BINARY_DIR}/$\{build_configuration\};--expt-relaxed-constexpr)
-    set(CUDA_NVCC_FLAGS ${CUDA_NVCC_FLAGS};-ftz=true)  # Flush denormals to zero
-    set(CUDA_INCLUDE ${CUDA_TOOLKIT_TARGET_DIR} ${CUDA_TOOLKIT_TARGET_DIR}/extras/CUPTI/include)
-    include_directories(${CUDA_INCLUDE})
-    add_definitions(-DGOOGLE_CUDA=1 -DTF_EXTRA_CUDA_CAPABILITIES=3.0,3.5,5.2)
-
-    # add cudnn
     if(NOT CUDNN_HOME)
       set(CUDNN_HOME ${CUDA_TOOLKIT_TARGET_DIR})
     endif(NOT CUDNN_HOME)
     include_directories(${CUDNN_HOME})
     set(CUDA_LIBRARIES ${CUDA_LIBRARIES} ${CUDA_CUDA_LIBRARY} ${CUDA_CUBLAS_LIBRARIES} ${CUDA_CUFFT_LIBRARIES}
       ${CUDA_curand_LIBRARY} ${CUDA_cupti_LIBRARY} ${CUDA_cusolver_LIBRARY} ${CUDNN_HOME}/lib/x64/cudnn.lib)
-
-    # create cuda_config.h
-    FILE(WRITE ${tensorflow_source_dir}/third_party/gpus/cuda/cuda_config.h
-      "#ifndef CUDA_CUDA_CONFIG_H_\n"
-      "#define CUDA_CUDA_CONFIG_H_\n"
-      "#define TF_CUDA_CAPABILITIES CudaVersion(\"3.0\"),CudaVersion(\"3.5\"),CudaVersion(\"5.2\")\n"
-      "#define TF_CUDA_VERSION \"64_80\"\n"
-      "#define TF_CUDNN_VERSION \"64_5\"\n"
-      "#define TF_CUDA_TOOLKIT_PATH \"${CUDA_TOOLKIT_ROOT_DIR}\"\n"
-      "#endif  // CUDA_CUDA_CONFIG_H_\n"
-    )
-
-    # tf assumes in various places header files to be in cuda/include. On windows the cuda sdk
-    # installs them under cuda/version/include and to avoid that we need to change tf we copy a
-    # few files to cuda/include
-    FILE(COPY
-      ${CUDA_TOOLKIT_TARGET_DIR}/include/cuda.h ${CUDA_TOOLKIT_TARGET_DIR}/include/cuComplex.h
-      ${CUDA_TOOLKIT_TARGET_DIR}/include/cublas_v2.h ${CUDNN_HOME}/include/cudnn.h
-      ${CUDA_TOOLKIT_TARGET_DIR}/include/cufft.h ${CUDA_TOOLKIT_TARGET_DIR}/include/curand.h
-      ${CUDA_TOOLKIT_TARGET_DIR}/include/cuda_runtime_api.h
-      ${CUDA_TOOLKIT_TARGET_DIR}/include/cusolverDn.h
-      DESTINATION ${tensorflow_source_dir}/third_party/gpus/cuda/include
-    )
-    include_directories(${tensorflow_source_dir}/third_party/gpus)
-    # add cuda libraries to tensorflow_EXTERNAL_LIBRARIES
-    list(APPEND tensorflow_EXTERNAL_LIBRARIES ${CUDA_LIBRARIES})
+  elseif(UNIX)
+    set(CUDA_LIBRARIES ${CUDA_LIBRARIES} ${CUDA_CUDA_LIBRARY} ${CUDA_CUBLAS_LIBRARIES} ${CUDA_CUFFT_LIBRARIES}
+      ${CUDA_curand_LIBRARY} ${CUDA_cupti_LIBRARY} ${CUDA_cusolver_LIBRARY} ${CUDNN_HOME}/lib/libcudnn.so)
   endif()
+
+  # create cuda_config.h
+  FILE(WRITE ${tensorflow_source_dir}/third_party/gpus/cuda/cuda_config.h
+    "#ifndef CUDA_CUDA_CONFIG_H_\n"
+    "#define CUDA_CUDA_CONFIG_H_\n"
+    "#define TF_CUDA_CAPABILITIES ${TF_CUDA_CAPABILITIES}\n"
+    "#define TF_CUDA_VERSION \"${TF_CUDA_VERSION}\"\n"
+    "#define TF_CUDNN_VERSION \"${TF_CUDNN_VERSION}\"\n"
+    "#define TF_CUDA_TOOLKIT_PATH \"${CUDA_TOOLKIT_ROOT_DIR}\"\n"
+    "#endif  // CUDA_CUDA_CONFIG_H_\n"
+  )
+
+  if(UNIX)
+    execute_process(COMMAND ln -snf "${CUDA_TOOLKIT_TARGET_DIR}/extras" "${tensorflow_source_dir}/third_party/gpus/cuda/")
+  endif(UNIX)
+
+  # tf assumes in various places header files to be in cuda/include. On windows the cuda sdk
+  # installs them under cuda/version/include and to avoid that we need to change tf we copy a
+  # few files to cuda/include
+  FILE(COPY
+    ${CUDA_TOOLKIT_TARGET_DIR}/include/cuda.h ${CUDA_TOOLKIT_TARGET_DIR}/include/cuComplex.h
+    ${CUDA_TOOLKIT_TARGET_DIR}/include/cublas_v2.h ${CUDNN_HOME}/include/cudnn.h
+    ${CUDA_TOOLKIT_TARGET_DIR}/include/cufft.h ${CUDA_TOOLKIT_TARGET_DIR}/include/curand.h
+    ${CUDA_TOOLKIT_TARGET_DIR}/include/cuda_runtime_api.h
+    ${CUDA_TOOLKIT_TARGET_DIR}/include/cusolverDn.h
+    DESTINATION ${tensorflow_source_dir}/third_party/gpus/cuda/include
+  )
+  include_directories(${tensorflow_source_dir}/third_party/gpus)
+  FILE(COPY
+    ${NCCL_INCLUDES}
+    DESTINATION ${CMAKE_CURRENT_BINARY_DIR}/external/nccl_archive/src/
+  )
+  # add cuda libraries to tensorflow_EXTERNAL_LIBRARIES
+  list(APPEND tensorflow_EXTERNAL_LIBRARIES ${CUDA_LIBRARIES})
 endif()
 
 # Find python executable
@@ -262,9 +351,7 @@ include(tf_core_framework.cmake)
 # NOTE: Disabled until issue #3996 is fixed.
 # include(tf_stream_executor.cmake)
 if (tensorflow_ENABLE_GPU)
-  if (WIN32)
-    include(tf_stream_executor.cmake)
-  endif()
+  include(tf_stream_executor.cmake)
 endif()
 
 include(tf_core_cpu.cmake)
@@ -293,3 +380,14 @@ endif()
 if(tensorflow_BUILD_CC_TESTS OR tensorflow_BUILD_PYTHON_TESTS)
   include(tf_tests.cmake)
 endif()
+
+MESSAGE(STATUS "<<< Gentoo configuration >>>
+Build type      ${CMAKE_BUILD_TYPE}
+Install path    ${CMAKE_INSTALL_PREFIX}
+Compiler flags:
+C               ${CMAKE_C_FLAGS}
+C++             ${CMAKE_CXX_FLAGS}
+Linker flags:
+Executable      ${CMAKE_EXE_LINKER_FLAGS}
+Module          ${CMAKE_MODULE_LINKER_FLAGS}
+Shared          ${CMAKE_SHARED_LINKER_FLAGS}\n")
diff --git a/tensorflow/contrib/cmake/external/eigen.cmake b/tensorflow/contrib/cmake/external/eigen.cmake
index 45a0096..c7213ec 100644
--- a/tensorflow/contrib/cmake/external/eigen.cmake
+++ b/tensorflow/contrib/cmake/external/eigen.cmake
@@ -45,6 +45,7 @@ ExternalProject_Add(eigen
     URL ${eigen_URL}
     DOWNLOAD_DIR "${DOWNLOAD_LOCATION}"
     INSTALL_DIR "${eigen_INSTALL}"
+    PATCH_COMMAND ${CMAKE_COMMAND} -E copy_if_different ${CMAKE_CURRENT_SOURCE_DIR}/patches/eigen/Macros.h ${eigen_BUILD}/Eigen/src/Core/util/Macros.h
     CMAKE_CACHE_ARGS
         -DCMAKE_BUILD_TYPE:STRING=Release
         -DCMAKE_VERBOSE_MAKEFILE:BOOL=OFF
diff --git a/tensorflow/contrib/cmake/external/gemmlowp.cmake b/tensorflow/contrib/cmake/external/gemmlowp.cmake
index eee61ff..68b4f56 100644
--- a/tensorflow/contrib/cmake/external/gemmlowp.cmake
+++ b/tensorflow/contrib/cmake/external/gemmlowp.cmake
@@ -15,7 +15,7 @@
 include (ExternalProject)
 
 set(gemmlowp_URL http://github.com/google/gemmlowp/archive/a6f29d8ac48d63293f845f2253eccbf86bc28321.tar.gz)
-set(gemmlowp_HASH SHA256=75d40ea8e68b0d1644f052fffe8f14a410b2a73d40ccb859a95c0578d194ec26)
+set(gemmlowp_HASH SHA256=1e40863d9f15dd6b15f8f18f49c500944be6118d9fe17e9dc58a1c709cadbb8a ) 
 set(gemmlowp_BUILD ${CMAKE_CURRENT_BINARY_DIR}/gemmlowp/src/gemmlowp)
 set(gemmlowp_INCLUDE_DIR ${CMAKE_CURRENT_BINARY_DIR}/gemmlowp/src/gemmlowp)
 
diff --git a/tensorflow/contrib/cmake/patches/eigen/Macros.h b/tensorflow/contrib/cmake/patches/eigen/Macros.h
index e69de29..6934bab 100644
--- /dev/null
+++ b/tensorflow/contrib/cmake/patches/eigen/Macros.h
@@ -0,0 +1,1018 @@
+// This file is part of Eigen, a lightweight C++ template library
+// for linear algebra.
+//
+// Copyright (C) 2008-2015 Gael Guennebaud <gael.guennebaud@inria.fr>
+// Copyright (C) 2006-2008 Benoit Jacob <jacob.benoit.1@gmail.com>
+//
+// This Source Code Form is subject to the terms of the Mozilla
+// Public License v. 2.0. If a copy of the MPL was not distributed
+// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
+
+#ifndef EIGEN_MACROS_H
+#define EIGEN_MACROS_H
+
+#define EIGEN_WORLD_VERSION 3
+#define EIGEN_MAJOR_VERSION 3
+#define EIGEN_MINOR_VERSION 90
+
+#define EIGEN_VERSION_AT_LEAST(x,y,z) (EIGEN_WORLD_VERSION>x || (EIGEN_WORLD_VERSION>=x && \
+                                      (EIGEN_MAJOR_VERSION>y || (EIGEN_MAJOR_VERSION>=y && \
+                                                                 EIGEN_MINOR_VERSION>=z))))
+
+// Compiler identification, EIGEN_COMP_*
+
+/// \internal EIGEN_COMP_GNUC set to 1 for all compilers compatible with GCC
+#ifdef __GNUC__
+  #define EIGEN_COMP_GNUC (__GNUC__*10+__GNUC_MINOR__)
+#else
+  #define EIGEN_COMP_GNUC 0
+#endif
+
+/// \internal EIGEN_COMP_CLANG set to major+minor version (e.g., 307 for clang 3.7) if the compiler is clang
+#if defined(__clang__)
+  #define EIGEN_COMP_CLANG (__clang_major__*100+__clang_minor__)
+#else
+  #define EIGEN_COMP_CLANG 0
+#endif
+
+
+/// \internal EIGEN_COMP_LLVM set to 1 if the compiler backend is llvm
+#if defined(__llvm__)
+  #define EIGEN_COMP_LLVM 1
+#else
+  #define EIGEN_COMP_LLVM 0
+#endif
+
+/// \internal EIGEN_COMP_ICC set to __INTEL_COMPILER if the compiler is Intel compiler, 0 otherwise
+#if defined(__INTEL_COMPILER)
+  #define EIGEN_COMP_ICC __INTEL_COMPILER
+#else
+  #define EIGEN_COMP_ICC 0
+#endif
+
+/// \internal EIGEN_COMP_MINGW set to 1 if the compiler is mingw
+#if defined(__MINGW32__)
+  #define EIGEN_COMP_MINGW 1
+#else
+  #define EIGEN_COMP_MINGW 0
+#endif
+
+/// \internal EIGEN_COMP_SUNCC set to 1 if the compiler is Solaris Studio
+#if defined(__SUNPRO_CC)
+  #define EIGEN_COMP_SUNCC 1
+#else
+  #define EIGEN_COMP_SUNCC 0
+#endif
+
+/// \internal EIGEN_COMP_MSVC set to _MSC_VER if the compiler is Microsoft Visual C++, 0 otherwise.
+#if defined(_MSC_VER)
+  #define EIGEN_COMP_MSVC _MSC_VER
+#else
+  #define EIGEN_COMP_MSVC 0
+#endif
+
+// For the record, here is a table summarizing the possible values for EIGEN_COMP_MSVC:
+//  name  ver   MSC_VER
+//  2008    9      1500
+//  2010   10      1600
+//  2012   11      1700
+//  2013   12      1800
+//  2015   14      1900
+//  "15"   15      1900
+
+/// \internal EIGEN_COMP_MSVC_STRICT set to 1 if the compiler is really Microsoft Visual C++ and not ,e.g., ICC or clang-cl
+#if EIGEN_COMP_MSVC && !(EIGEN_COMP_ICC || EIGEN_COMP_LLVM || EIGEN_COMP_CLANG)
+  #define EIGEN_COMP_MSVC_STRICT _MSC_VER
+#else
+  #define EIGEN_COMP_MSVC_STRICT 0
+#endif
+
+/// \internal EIGEN_COMP_IBM set to 1 if the compiler is IBM XL C++
+#if defined(__IBMCPP__) || defined(__xlc__)
+  #define EIGEN_COMP_IBM 1
+#else
+  #define EIGEN_COMP_IBM 0
+#endif
+
+/// \internal EIGEN_COMP_PGI set to 1 if the compiler is Portland Group Compiler
+#if defined(__PGI)
+  #define EIGEN_COMP_PGI 1
+#else
+  #define EIGEN_COMP_PGI 0
+#endif
+
+/// \internal EIGEN_COMP_ARM set to 1 if the compiler is ARM Compiler
+#if defined(__CC_ARM) || defined(__ARMCC_VERSION)
+  #define EIGEN_COMP_ARM 1
+#else
+  #define EIGEN_COMP_ARM 0
+#endif
+
+/// \internal EIGEN_COMP_ARM set to 1 if the compiler is ARM Compiler
+#if defined(__EMSCRIPTEN__)
+  #define EIGEN_COMP_EMSCRIPTEN 1
+#else
+  #define EIGEN_COMP_EMSCRIPTEN 0
+#endif
+
+
+/// \internal EIGEN_GNUC_STRICT set to 1 if the compiler is really GCC and not a compatible compiler (e.g., ICC, clang, mingw, etc.)
+#if EIGEN_COMP_GNUC && !(EIGEN_COMP_CLANG || EIGEN_COMP_ICC || EIGEN_COMP_MINGW || EIGEN_COMP_PGI || EIGEN_COMP_IBM || EIGEN_COMP_ARM || EIGEN_COMP_EMSCRIPTEN)
+  #define EIGEN_COMP_GNUC_STRICT 1
+#else
+  #define EIGEN_COMP_GNUC_STRICT 0
+#endif
+
+
+#if EIGEN_COMP_GNUC
+  #define EIGEN_GNUC_AT_LEAST(x,y) ((__GNUC__==x && __GNUC_MINOR__>=y) || __GNUC__>x)
+  #define EIGEN_GNUC_AT_MOST(x,y)  ((__GNUC__==x && __GNUC_MINOR__<=y) || __GNUC__<x)
+  #define EIGEN_GNUC_AT(x,y)       ( __GNUC__==x && __GNUC_MINOR__==y )
+#else
+  #define EIGEN_GNUC_AT_LEAST(x,y) 0
+  #define EIGEN_GNUC_AT_MOST(x,y)  0
+  #define EIGEN_GNUC_AT(x,y)       0
+#endif
+
+// FIXME: could probably be removed as we do not support gcc 3.x anymore
+#if EIGEN_COMP_GNUC && (__GNUC__ <= 3)
+#define EIGEN_GCC3_OR_OLDER 1
+#else
+#define EIGEN_GCC3_OR_OLDER 0
+#endif
+
+
+// Architecture identification, EIGEN_ARCH_*
+
+#if defined(__x86_64__) || defined(_M_X64) || defined(__amd64)
+  #define EIGEN_ARCH_x86_64 1
+#else
+  #define EIGEN_ARCH_x86_64 0
+#endif
+
+#if defined(__i386__) || defined(_M_IX86) || defined(_X86_) || defined(__i386)
+  #define EIGEN_ARCH_i386 1
+#else
+  #define EIGEN_ARCH_i386 0
+#endif
+
+#if EIGEN_ARCH_x86_64 || EIGEN_ARCH_i386
+  #define EIGEN_ARCH_i386_OR_x86_64 1
+#else
+  #define EIGEN_ARCH_i386_OR_x86_64 0
+#endif
+
+/// \internal EIGEN_ARCH_ARM set to 1 if the architecture is ARM
+#if defined(__arm__)
+  #define EIGEN_ARCH_ARM 1
+#else
+  #define EIGEN_ARCH_ARM 0
+#endif
+
+/// \internal EIGEN_ARCH_ARM64 set to 1 if the architecture is ARM64
+#if defined(__aarch64__)
+  #define EIGEN_ARCH_ARM64 1
+#else
+  #define EIGEN_ARCH_ARM64 0
+#endif
+
+#if EIGEN_ARCH_ARM || EIGEN_ARCH_ARM64
+  #define EIGEN_ARCH_ARM_OR_ARM64 1
+#else
+  #define EIGEN_ARCH_ARM_OR_ARM64 0
+#endif
+
+/// \internal EIGEN_ARCH_MIPS set to 1 if the architecture is MIPS
+#if defined(__mips__) || defined(__mips)
+  #define EIGEN_ARCH_MIPS 1
+#else
+  #define EIGEN_ARCH_MIPS 0
+#endif
+
+/// \internal EIGEN_ARCH_SPARC set to 1 if the architecture is SPARC
+#if defined(__sparc__) || defined(__sparc)
+  #define EIGEN_ARCH_SPARC 1
+#else
+  #define EIGEN_ARCH_SPARC 0
+#endif
+
+/// \internal EIGEN_ARCH_IA64 set to 1 if the architecture is Intel Itanium
+#if defined(__ia64__)
+  #define EIGEN_ARCH_IA64 1
+#else
+  #define EIGEN_ARCH_IA64 0
+#endif
+
+/// \internal EIGEN_ARCH_PPC set to 1 if the architecture is PowerPC
+#if defined(__powerpc__) || defined(__ppc__) || defined(_M_PPC)
+  #define EIGEN_ARCH_PPC 1
+#else
+  #define EIGEN_ARCH_PPC 0
+#endif
+
+
+
+// Operating system identification, EIGEN_OS_*
+
+/// \internal EIGEN_OS_UNIX set to 1 if the OS is a unix variant
+#if defined(__unix__) || defined(__unix)
+  #define EIGEN_OS_UNIX 1
+#else
+  #define EIGEN_OS_UNIX 0
+#endif
+
+/// \internal EIGEN_OS_LINUX set to 1 if the OS is based on Linux kernel
+#if defined(__linux__)
+  #define EIGEN_OS_LINUX 1
+#else
+  #define EIGEN_OS_LINUX 0
+#endif
+
+/// \internal EIGEN_OS_ANDROID set to 1 if the OS is Android
+// note: ANDROID is defined when using ndk_build, __ANDROID__ is defined when using a standalone toolchain.
+#if defined(__ANDROID__) || defined(ANDROID)
+  #define EIGEN_OS_ANDROID 1
+#else
+  #define EIGEN_OS_ANDROID 0
+#endif
+
+/// \internal EIGEN_OS_GNULINUX set to 1 if the OS is GNU Linux and not Linux-based OS (e.g., not android)
+#if defined(__gnu_linux__) && !(EIGEN_OS_ANDROID)
+  #define EIGEN_OS_GNULINUX 1
+#else
+  #define EIGEN_OS_GNULINUX 0
+#endif
+
+/// \internal EIGEN_OS_BSD set to 1 if the OS is a BSD variant
+#if defined(__FreeBSD__) || defined(__NetBSD__) || defined(__OpenBSD__) || defined(__bsdi__) || defined(__DragonFly__)
+  #define EIGEN_OS_BSD 1
+#else
+  #define EIGEN_OS_BSD 0
+#endif
+
+/// \internal EIGEN_OS_MAC set to 1 if the OS is MacOS
+#if defined(__APPLE__)
+  #define EIGEN_OS_MAC 1
+#else
+  #define EIGEN_OS_MAC 0
+#endif
+
+/// \internal EIGEN_OS_QNX set to 1 if the OS is QNX
+#if defined(__QNX__)
+  #define EIGEN_OS_QNX 1
+#else
+  #define EIGEN_OS_QNX 0
+#endif
+
+/// \internal EIGEN_OS_WIN set to 1 if the OS is Windows based
+#if defined(_WIN32)
+  #define EIGEN_OS_WIN 1
+#else
+  #define EIGEN_OS_WIN 0
+#endif
+
+/// \internal EIGEN_OS_WIN64 set to 1 if the OS is Windows 64bits
+#if defined(_WIN64)
+  #define EIGEN_OS_WIN64 1
+#else
+  #define EIGEN_OS_WIN64 0
+#endif
+
+/// \internal EIGEN_OS_WINCE set to 1 if the OS is Windows CE
+#if defined(_WIN32_WCE)
+  #define EIGEN_OS_WINCE 1
+#else
+  #define EIGEN_OS_WINCE 0
+#endif
+
+/// \internal EIGEN_OS_CYGWIN set to 1 if the OS is Windows/Cygwin
+#if defined(__CYGWIN__)
+  #define EIGEN_OS_CYGWIN 1
+#else
+  #define EIGEN_OS_CYGWIN 0
+#endif
+
+/// \internal EIGEN_OS_WIN_STRICT set to 1 if the OS is really Windows and not some variants
+#if EIGEN_OS_WIN && !( EIGEN_OS_WINCE || EIGEN_OS_CYGWIN )
+  #define EIGEN_OS_WIN_STRICT 1
+#else
+  #define EIGEN_OS_WIN_STRICT 0
+#endif
+
+/// \internal EIGEN_OS_SUN set to 1 if the OS is SUN
+#if (defined(sun) || defined(__sun)) && !(defined(__SVR4) || defined(__svr4__))
+  #define EIGEN_OS_SUN 1
+#else
+  #define EIGEN_OS_SUN 0
+#endif
+
+/// \internal EIGEN_OS_SOLARIS set to 1 if the OS is Solaris
+#if (defined(sun) || defined(__sun)) && (defined(__SVR4) || defined(__svr4__))
+  #define EIGEN_OS_SOLARIS 1
+#else
+  #define EIGEN_OS_SOLARIS 0
+#endif
+
+
+
+#if EIGEN_GNUC_AT_MOST(4,3) && !EIGEN_COMP_CLANG
+  // see bug 89
+  #define EIGEN_SAFE_TO_USE_STANDARD_ASSERT_MACRO 0
+#else
+  #define EIGEN_SAFE_TO_USE_STANDARD_ASSERT_MACRO 1
+#endif
+
+// This macro can be used to prevent from macro expansion, e.g.:
+//   std::max EIGEN_NOT_A_MACRO(a,b)
+#define EIGEN_NOT_A_MACRO
+
+#ifdef EIGEN_DEFAULT_TO_ROW_MAJOR
+#define EIGEN_DEFAULT_MATRIX_STORAGE_ORDER_OPTION Eigen::RowMajor
+#else
+#define EIGEN_DEFAULT_MATRIX_STORAGE_ORDER_OPTION Eigen::ColMajor
+#endif
+
+#ifndef EIGEN_DEFAULT_DENSE_INDEX_TYPE
+#define EIGEN_DEFAULT_DENSE_INDEX_TYPE std::ptrdiff_t
+#endif
+
+// Cross compiler wrapper around LLVM's __has_builtin
+#ifdef __has_builtin
+#  define EIGEN_HAS_BUILTIN(x) __has_builtin(x)
+#else
+#  define EIGEN_HAS_BUILTIN(x) 0
+#endif
+
+// A Clang feature extension to determine compiler features.
+// We use it to determine 'cxx_rvalue_references'
+#ifndef __has_feature
+# define __has_feature(x) 0
+#endif
+
+// Some old compilers do not support template specializations like:
+// template<typename T,int N> void foo(const T x[N]);
+#if !( EIGEN_COMP_CLANG && ((EIGEN_COMP_CLANG<309) || defined(__apple_build_version__)) || EIGEN_COMP_GNUC_STRICT && EIGEN_COMP_GNUC<49)
+#define EIGEN_HAS_STATIC_ARRAY_TEMPLATE 1
+#else
+#define EIGEN_HAS_STATIC_ARRAY_TEMPLATE 0
+#endif
+
+// Upperbound on the C++ version to use.
+// Expected values are 03, 11, 14, 17, etc.
+// By default, let's use an arbitrarily large C++ version.
+#ifndef EIGEN_MAX_CPP_VER
+#define EIGEN_MAX_CPP_VER 99
+#endif
+
+#if EIGEN_MAX_CPP_VER>=11 && (defined(__cplusplus) && (__cplusplus >= 201103L) || EIGEN_COMP_MSVC >= 1900)
+#define EIGEN_HAS_CXX11 1
+#else
+#define EIGEN_HAS_CXX11 0
+#endif
+
+#if EIGEN_MAX_CPP_VER>=14 && (defined(__cplusplus) && (__cplusplus > 201402L) || EIGEN_COMP_MSVC >= 1910)
+#define EIGEN_HAS_CXX14 1
+#else
+#define EIGEN_HAS_CXX14 0
+#endif
+
+// Do we support r-value references?
+#ifndef EIGEN_HAS_RVALUE_REFERENCES
+#if EIGEN_MAX_CPP_VER>=11 && \
+    (__has_feature(cxx_rvalue_references) || \
+    (defined(__cplusplus) && __cplusplus >= 201103L) || \
+    (EIGEN_COMP_MSVC >= 1600))
+  #define EIGEN_HAS_RVALUE_REFERENCES 1
+#else
+  #define EIGEN_HAS_RVALUE_REFERENCES 0
+#endif
+#endif
+
+// Does the compiler support C99?
+#ifndef EIGEN_HAS_C99_MATH
+#if EIGEN_MAX_CPP_VER>=11 && \
+    ((defined(__STDC_VERSION__) && (__STDC_VERSION__ >= 199901))       \
+  || (defined(__GNUC__) && defined(_GLIBCXX_USE_C99)) \
+  || (defined(_LIBCPP_VERSION) && !defined(_MSC_VER)) \
+  || (EIGEN_COMP_MSVC >= 1900) || defined(__SYCL_DEVICE_ONLY__))
+  #define EIGEN_HAS_C99_MATH 1
+#else
+  #define EIGEN_HAS_C99_MATH 0
+#endif
+#endif
+
+// Does the compiler support result_of?
+#ifndef EIGEN_HAS_STD_RESULT_OF
+#if EIGEN_MAX_CPP_VER>=11 && ((__has_feature(cxx_lambdas) || (defined(__cplusplus) && __cplusplus >= 201103L)))
+#define EIGEN_HAS_STD_RESULT_OF 1
+#else
+#define EIGEN_HAS_STD_RESULT_OF 0
+#endif
+#endif
+
+// Does the compiler support variadic templates?
+#ifndef EIGEN_HAS_VARIADIC_TEMPLATES
+#if EIGEN_MAX_CPP_VER>=11 && (__cplusplus > 199711L || EIGEN_COMP_MSVC >= 1900) \
+  && (!defined(__NVCC__) || !EIGEN_ARCH_ARM_OR_ARM64 || (defined __CUDACC_VER__ && __CUDACC_VER__ >= 80000) )
+    // ^^ Disable the use of variadic templates when compiling with versions of nvcc older than 8.0 on ARM devices:
+    //    this prevents nvcc from crashing when compiling Eigen on Tegra X1
+#define EIGEN_HAS_VARIADIC_TEMPLATES 1
+#elif  EIGEN_MAX_CPP_VER>=11 && (__cplusplus > 199711L || EIGEN_COMP_MSVC >= 1900) && defined(__SYCL_DEVICE_ONLY__)
+#define EIGEN_HAS_VARIADIC_TEMPLATES 1
+#else
+#define EIGEN_HAS_VARIADIC_TEMPLATES 0
+#endif
+#endif
+
+// Does the compiler fully support const expressions? (as in c++14)
+#ifndef EIGEN_HAS_CONSTEXPR
+
+#if defined(__CUDACC__)
+// Const expressions are supported provided that c++11 is enabled and we're using either clang or nvcc 7.5 or above
+#if EIGEN_MAX_CPP_VER>=14 && (__cplusplus > 199711L && defined(__CUDACC_VER__) && (EIGEN_COMP_CLANG || __CUDACC_VER__ >= 70500))
+  #define EIGEN_HAS_CONSTEXPR 1
+#endif
+#elif EIGEN_MAX_CPP_VER>=14 && (__has_feature(cxx_relaxed_constexpr) || (defined(__cplusplus) && __cplusplus >= 201402L) || \
+  (EIGEN_GNUC_AT_LEAST(4,8) && (__cplusplus > 199711L)) || \
+  (EIGEN_COMP_CLANG >= 306 && (__cplusplus > 199711L)))
+#define EIGEN_HAS_CONSTEXPR 1
+#endif
+
+#ifndef EIGEN_HAS_CONSTEXPR
+#define EIGEN_HAS_CONSTEXPR 0
+#endif
+
+#endif
+
+// Does the compiler support C++11 math?
+// Let's be conservative and enable the default C++11 implementation only if we are sure it exists
+#ifndef EIGEN_HAS_CXX11_MATH
+  #if EIGEN_MAX_CPP_VER>=11 && ((__cplusplus > 201103L) || (__cplusplus >= 201103L) && (EIGEN_COMP_GNUC_STRICT || EIGEN_COMP_CLANG || EIGEN_COMP_MSVC || EIGEN_COMP_ICC)  \
+      && (EIGEN_ARCH_i386_OR_x86_64) && (EIGEN_OS_GNULINUX || EIGEN_OS_WIN_STRICT || EIGEN_OS_MAC))
+    #define EIGEN_HAS_CXX11_MATH 1
+  #else
+    #define EIGEN_HAS_CXX11_MATH 0
+  #endif
+#endif
+
+// Does the compiler support proper C++11 containers?
+#ifndef EIGEN_HAS_CXX11_CONTAINERS
+  #if    EIGEN_MAX_CPP_VER>=11 && \
+         ((__cplusplus > 201103L) \
+      || ((__cplusplus >= 201103L) && (EIGEN_COMP_GNUC_STRICT || EIGEN_COMP_CLANG || EIGEN_COMP_ICC>=1400)) \
+      || EIGEN_COMP_MSVC >= 1900)
+    #define EIGEN_HAS_CXX11_CONTAINERS 1
+  #else
+    #define EIGEN_HAS_CXX11_CONTAINERS 0
+  #endif
+#endif
+
+// Does the compiler support C++11 noexcept?
+#ifndef EIGEN_HAS_CXX11_NOEXCEPT
+  #if    EIGEN_MAX_CPP_VER>=11 && \
+         (__has_feature(cxx_noexcept) \
+      || (__cplusplus > 201103L) \
+      || ((__cplusplus >= 201103L) && (EIGEN_COMP_GNUC_STRICT || EIGEN_COMP_CLANG || EIGEN_COMP_ICC>=1400)) \
+      || EIGEN_COMP_MSVC >= 1900)
+    #define EIGEN_HAS_CXX11_NOEXCEPT 1
+  #else
+    #define EIGEN_HAS_CXX11_NOEXCEPT 0
+  #endif
+#endif
+
+/** Allows to disable some optimizations which might affect the accuracy of the result.
+  * Such optimization are enabled by default, and set EIGEN_FAST_MATH to 0 to disable them.
+  * They currently include:
+  *   - single precision ArrayBase::sin() and ArrayBase::cos() for SSE and AVX vectorization.
+  */
+#ifndef EIGEN_FAST_MATH
+#define EIGEN_FAST_MATH 1
+#endif
+
+#define EIGEN_DEBUG_VAR(x) std::cerr << #x << " = " << x << std::endl;
+
+// concatenate two tokens
+#define EIGEN_CAT2(a,b) a ## b
+#define EIGEN_CAT(a,b) EIGEN_CAT2(a,b)
+
+#define EIGEN_COMMA ,
+
+// convert a token to a string
+#define EIGEN_MAKESTRING2(a) #a
+#define EIGEN_MAKESTRING(a) EIGEN_MAKESTRING2(a)
+
+// EIGEN_STRONG_INLINE is a stronger version of the inline, using __forceinline on MSVC,
+// but it still doesn't use GCC's always_inline. This is useful in (common) situations where MSVC needs forceinline
+// but GCC is still doing fine with just inline.
+#if EIGEN_COMP_MSVC || EIGEN_COMP_ICC
+#define EIGEN_STRONG_INLINE __forceinline
+#else
+#define EIGEN_STRONG_INLINE inline
+#endif
+
+// EIGEN_ALWAYS_INLINE is the stronget, it has the effect of making the function inline and adding every possible
+// attribute to maximize inlining. This should only be used when really necessary: in particular,
+// it uses __attribute__((always_inline)) on GCC, which most of the time is useless and can severely harm compile times.
+// FIXME with the always_inline attribute,
+// gcc 3.4.x and 4.1 reports the following compilation error:
+//   Eval.h:91: sorry, unimplemented: inlining failed in call to 'const Eigen::Eval<Derived> Eigen::MatrixBase<Scalar, Derived>::eval() const'
+//    : function body not available
+//   See also bug 1367
+#if EIGEN_GNUC_AT_LEAST(4,2)
+#define EIGEN_ALWAYS_INLINE __attribute__((always_inline)) inline
+#else
+#define EIGEN_ALWAYS_INLINE EIGEN_STRONG_INLINE
+#endif
+
+#if EIGEN_COMP_GNUC
+#define EIGEN_DONT_INLINE __attribute__((noinline))
+#elif EIGEN_COMP_MSVC
+#define EIGEN_DONT_INLINE __declspec(noinline)
+#else
+#define EIGEN_DONT_INLINE
+#endif
+
+#if EIGEN_COMP_GNUC
+#define EIGEN_PERMISSIVE_EXPR __extension__
+#else
+#define EIGEN_PERMISSIVE_EXPR
+#endif
+
+// this macro allows to get rid of linking errors about multiply defined functions.
+//  - static is not very good because it prevents definitions from different object files to be merged.
+//           So static causes the resulting linked executable to be bloated with multiple copies of the same function.
+//  - inline is not perfect either as it unwantedly hints the compiler toward inlining the function.
+#define EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_DEVICE_FUNC
+#define EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_DEVICE_FUNC inline
+
+#ifdef NDEBUG
+# ifndef EIGEN_NO_DEBUG
+#  define EIGEN_NO_DEBUG
+# endif
+#endif
+
+// eigen_plain_assert is where we implement the workaround for the assert() bug in GCC <= 4.3, see bug 89
+#ifdef EIGEN_NO_DEBUG
+  #define eigen_plain_assert(x)
+#else
+  #if EIGEN_SAFE_TO_USE_STANDARD_ASSERT_MACRO
+    namespace Eigen {
+    namespace internal {
+    inline bool copy_bool(bool b) { return b; }
+    }
+    }
+    #define eigen_plain_assert(x) assert(x)
+  #else
+    // work around bug 89
+    #include <cstdlib>   // for abort
+    #include <iostream>  // for std::cerr
+
+    namespace Eigen {
+    namespace internal {
+    // trivial function copying a bool. Must be EIGEN_DONT_INLINE, so we implement it after including Eigen headers.
+    // see bug 89.
+    namespace {
+    EIGEN_DONT_INLINE bool copy_bool(bool b) { return b; }
+    }
+    inline void assert_fail(const char *condition, const char *function, const char *file, int line)
+    {
+      std::cerr << "assertion failed: " << condition << " in function " << function << " at " << file << ":" << line << std::endl;
+      abort();
+    }
+    }
+    }
+    #define eigen_plain_assert(x) \
+      do { \
+        if(!Eigen::internal::copy_bool(x)) \
+          Eigen::internal::assert_fail(EIGEN_MAKESTRING(x), __PRETTY_FUNCTION__, __FILE__, __LINE__); \
+      } while(false)
+  #endif
+#endif
+
+// eigen_assert can be overridden
+#ifndef eigen_assert
+#define eigen_assert(x) eigen_plain_assert(x)
+#endif
+
+#ifdef EIGEN_INTERNAL_DEBUGGING
+#define eigen_internal_assert(x) eigen_assert(x)
+#else
+#define eigen_internal_assert(x)
+#endif
+
+#ifdef EIGEN_NO_DEBUG
+#define EIGEN_ONLY_USED_FOR_DEBUG(x) EIGEN_UNUSED_VARIABLE(x)
+#else
+#define EIGEN_ONLY_USED_FOR_DEBUG(x)
+#endif
+
+#ifndef EIGEN_NO_DEPRECATED_WARNING
+  #if EIGEN_COMP_GNUC
+    #define EIGEN_DEPRECATED __attribute__((deprecated))
+  #elif EIGEN_COMP_MSVC
+    #define EIGEN_DEPRECATED __declspec(deprecated)
+  #else
+    #define EIGEN_DEPRECATED
+  #endif
+#else
+  #define EIGEN_DEPRECATED
+#endif
+
+#if EIGEN_COMP_GNUC
+#define EIGEN_UNUSED __attribute__((unused))
+#else
+#define EIGEN_UNUSED
+#endif
+
+// Suppresses 'unused variable' warnings.
+namespace Eigen {
+  namespace internal {
+    template<typename T> EIGEN_DEVICE_FUNC void ignore_unused_variable(const T&) {}
+  }
+}
+#define EIGEN_UNUSED_VARIABLE(var) Eigen::internal::ignore_unused_variable(var);
+
+#if !defined(EIGEN_ASM_COMMENT)
+  #if EIGEN_COMP_GNUC && (EIGEN_ARCH_i386_OR_x86_64 || EIGEN_ARCH_ARM_OR_ARM64)
+    #define EIGEN_ASM_COMMENT(X)  __asm__("#" X)
+  #else
+    #define EIGEN_ASM_COMMENT(X)
+  #endif
+#endif
+
+
+#if EIGEN_COMP_MSVC
+  // NOTE MSVC often gives C4127 warnings with compiletime if statements. See bug 1362.
+  // This workaround is ugly, but it does the job.
+#  define EIGEN_CONST_CONDITIONAL(cond)  (void)0, cond
+#else
+#  define EIGEN_CONST_CONDITIONAL(cond)  cond
+#endif
+
+//------------------------------------------------------------------------------------------
+// Static and dynamic alignment control
+//
+// The main purpose of this section is to define EIGEN_MAX_ALIGN_BYTES and EIGEN_MAX_STATIC_ALIGN_BYTES
+// as the maximal boundary in bytes on which dynamically and statically allocated data may be alignment respectively.
+// The values of EIGEN_MAX_ALIGN_BYTES and EIGEN_MAX_STATIC_ALIGN_BYTES can be specified by the user. If not,
+// a default value is automatically computed based on architecture, compiler, and OS.
+//
+// This section also defines macros EIGEN_ALIGN_TO_BOUNDARY(N) and the shortcuts EIGEN_ALIGN{8,16,32,_MAX}
+// to be used to declare statically aligned buffers.
+//------------------------------------------------------------------------------------------
+
+
+/* EIGEN_ALIGN_TO_BOUNDARY(n) forces data to be n-byte aligned. This is used to satisfy SIMD requirements.
+ * However, we do that EVEN if vectorization (EIGEN_VECTORIZE) is disabled,
+ * so that vectorization doesn't affect binary compatibility.
+ *
+ * If we made alignment depend on whether or not EIGEN_VECTORIZE is defined, it would be impossible to link
+ * vectorized and non-vectorized code.
+ */
+#if (defined __CUDACC__)
+  #define EIGEN_ALIGN_TO_BOUNDARY(n) __align__(n)
+#elif EIGEN_COMP_GNUC || EIGEN_COMP_PGI || EIGEN_COMP_IBM || EIGEN_COMP_ARM
+  #define EIGEN_ALIGN_TO_BOUNDARY(n) __attribute__((aligned(n)))
+#elif EIGEN_COMP_MSVC
+  #define EIGEN_ALIGN_TO_BOUNDARY(n) __declspec(align(n))
+#elif EIGEN_COMP_SUNCC
+  // FIXME not sure about this one:
+  #define EIGEN_ALIGN_TO_BOUNDARY(n) __attribute__((aligned(n)))
+#else
+  #error Please tell me what is the equivalent of __attribute__((aligned(n))) for your compiler
+#endif
+
+// If the user explicitly disable vectorization, then we also disable alignment
+#if defined(EIGEN_DONT_VECTORIZE)
+  #define EIGEN_IDEAL_MAX_ALIGN_BYTES 0
+#elif defined(EIGEN_VECTORIZE_AVX512)
+  // 64 bytes static alignmeent is preferred only if really required
+  #define EIGEN_IDEAL_MAX_ALIGN_BYTES 64
+#elif defined(__AVX__)
+  // 32 bytes static alignmeent is preferred only if really required
+  #define EIGEN_IDEAL_MAX_ALIGN_BYTES 32
+#else
+  #define EIGEN_IDEAL_MAX_ALIGN_BYTES 16
+#endif
+
+
+// EIGEN_MIN_ALIGN_BYTES defines the minimal value for which the notion of explicit alignment makes sense
+#define EIGEN_MIN_ALIGN_BYTES 16
+
+// Defined the boundary (in bytes) on which the data needs to be aligned. Note
+// that unless EIGEN_ALIGN is defined and not equal to 0, the data may not be
+// aligned at all regardless of the value of this #define.
+
+#if (defined(EIGEN_DONT_ALIGN_STATICALLY) || defined(EIGEN_DONT_ALIGN))  && defined(EIGEN_MAX_STATIC_ALIGN_BYTES) && EIGEN_MAX_STATIC_ALIGN_BYTES>0
+#error EIGEN_MAX_STATIC_ALIGN_BYTES and EIGEN_DONT_ALIGN[_STATICALLY] are both defined with EIGEN_MAX_STATIC_ALIGN_BYTES!=0. Use EIGEN_MAX_STATIC_ALIGN_BYTES=0 as a synonym of EIGEN_DONT_ALIGN_STATICALLY.
+#endif
+
+// EIGEN_DONT_ALIGN_STATICALLY and EIGEN_DONT_ALIGN are deprectated
+// They imply EIGEN_MAX_STATIC_ALIGN_BYTES=0
+#if defined(EIGEN_DONT_ALIGN_STATICALLY) || defined(EIGEN_DONT_ALIGN)
+  #ifdef EIGEN_MAX_STATIC_ALIGN_BYTES
+    #undef EIGEN_MAX_STATIC_ALIGN_BYTES
+  #endif
+  #define EIGEN_MAX_STATIC_ALIGN_BYTES 0
+#endif
+
+#ifndef EIGEN_MAX_STATIC_ALIGN_BYTES
+
+  // Try to automatically guess what is the best default value for EIGEN_MAX_STATIC_ALIGN_BYTES
+
+  // 16 byte alignment is only useful for vectorization. Since it affects the ABI, we need to enable
+  // 16 byte alignment on all platforms where vectorization might be enabled. In theory we could always
+  // enable alignment, but it can be a cause of problems on some platforms, so we just disable it in
+  // certain common platform (compiler+architecture combinations) to avoid these problems.
+  // Only static alignment is really problematic (relies on nonstandard compiler extensions),
+  // try to keep heap alignment even when we have to disable static alignment.
+  #if EIGEN_COMP_GNUC && !(EIGEN_ARCH_i386_OR_x86_64 || EIGEN_ARCH_ARM_OR_ARM64 || EIGEN_ARCH_PPC || EIGEN_ARCH_IA64)
+  #define EIGEN_GCC_AND_ARCH_DOESNT_WANT_STACK_ALIGNMENT 1
+  #elif EIGEN_ARCH_ARM_OR_ARM64 && EIGEN_COMP_GNUC_STRICT && EIGEN_GNUC_AT_MOST(4, 6)
+  // Old versions of GCC on ARM, at least 4.4, were once seen to have buggy static alignment support.
+  // Not sure which version fixed it, hopefully it doesn't affect 4.7, which is still somewhat in use.
+  // 4.8 and newer seem definitely unaffected.
+  #define EIGEN_GCC_AND_ARCH_DOESNT_WANT_STACK_ALIGNMENT 1
+  #else
+  #define EIGEN_GCC_AND_ARCH_DOESNT_WANT_STACK_ALIGNMENT 0
+  #endif
+
+  // static alignment is completely disabled with GCC 3, Sun Studio, and QCC/QNX
+  #if !EIGEN_GCC_AND_ARCH_DOESNT_WANT_STACK_ALIGNMENT \
+  && !EIGEN_GCC3_OR_OLDER \
+  && !EIGEN_COMP_SUNCC \
+  && !EIGEN_OS_QNX
+    #define EIGEN_ARCH_WANTS_STACK_ALIGNMENT 1
+  #else
+    #define EIGEN_ARCH_WANTS_STACK_ALIGNMENT 0
+  #endif
+
+  #if EIGEN_ARCH_WANTS_STACK_ALIGNMENT
+    #define EIGEN_MAX_STATIC_ALIGN_BYTES EIGEN_IDEAL_MAX_ALIGN_BYTES
+  #else
+    #define EIGEN_MAX_STATIC_ALIGN_BYTES 0
+  #endif
+
+#endif
+
+// If EIGEN_MAX_ALIGN_BYTES is defined, then it is considered as an upper bound for EIGEN_MAX_ALIGN_BYTES
+#if defined(EIGEN_MAX_ALIGN_BYTES) && EIGEN_MAX_ALIGN_BYTES<EIGEN_MAX_STATIC_ALIGN_BYTES
+#undef EIGEN_MAX_STATIC_ALIGN_BYTES
+#define EIGEN_MAX_STATIC_ALIGN_BYTES EIGEN_MAX_ALIGN_BYTES
+#endif
+
+#if EIGEN_MAX_STATIC_ALIGN_BYTES==0 && !defined(EIGEN_DISABLE_UNALIGNED_ARRAY_ASSERT)
+  #define EIGEN_DISABLE_UNALIGNED_ARRAY_ASSERT
+#endif
+
+// At this stage, EIGEN_MAX_STATIC_ALIGN_BYTES>0 is the true test whether we want to align arrays on the stack or not.
+// It takes into account both the user choice to explicitly enable/disable alignment (by settting EIGEN_MAX_STATIC_ALIGN_BYTES)
+// and the architecture config (EIGEN_ARCH_WANTS_STACK_ALIGNMENT).
+// Henceforth, only EIGEN_MAX_STATIC_ALIGN_BYTES should be used.
+
+
+// Shortcuts to EIGEN_ALIGN_TO_BOUNDARY
+#define EIGEN_ALIGN8  EIGEN_ALIGN_TO_BOUNDARY(8)
+#define EIGEN_ALIGN16 EIGEN_ALIGN_TO_BOUNDARY(16)
+#define EIGEN_ALIGN32 EIGEN_ALIGN_TO_BOUNDARY(32)
+#define EIGEN_ALIGN64 EIGEN_ALIGN_TO_BOUNDARY(64)
+#if EIGEN_MAX_STATIC_ALIGN_BYTES>0
+#define EIGEN_ALIGN_MAX EIGEN_ALIGN_TO_BOUNDARY(EIGEN_MAX_STATIC_ALIGN_BYTES)
+#else
+#define EIGEN_ALIGN_MAX
+#endif
+
+
+// Dynamic alignment control
+
+#if defined(EIGEN_DONT_ALIGN) && defined(EIGEN_MAX_ALIGN_BYTES) && EIGEN_MAX_ALIGN_BYTES>0
+#error EIGEN_MAX_ALIGN_BYTES and EIGEN_DONT_ALIGN are both defined with EIGEN_MAX_ALIGN_BYTES!=0. Use EIGEN_MAX_ALIGN_BYTES=0 as a synonym of EIGEN_DONT_ALIGN.
+#endif
+
+#ifdef EIGEN_DONT_ALIGN
+  #ifdef EIGEN_MAX_ALIGN_BYTES
+    #undef EIGEN_MAX_ALIGN_BYTES
+  #endif
+  #define EIGEN_MAX_ALIGN_BYTES 0
+#elif !defined(EIGEN_MAX_ALIGN_BYTES)
+  #define EIGEN_MAX_ALIGN_BYTES EIGEN_IDEAL_MAX_ALIGN_BYTES
+#endif
+
+#if EIGEN_IDEAL_MAX_ALIGN_BYTES > EIGEN_MAX_ALIGN_BYTES
+#define EIGEN_DEFAULT_ALIGN_BYTES EIGEN_IDEAL_MAX_ALIGN_BYTES
+#else
+#define EIGEN_DEFAULT_ALIGN_BYTES EIGEN_MAX_ALIGN_BYTES
+#endif
+
+
+#ifndef EIGEN_UNALIGNED_VECTORIZE
+#define EIGEN_UNALIGNED_VECTORIZE 1
+#endif
+
+//----------------------------------------------------------------------
+
+
+#ifdef EIGEN_DONT_USE_RESTRICT_KEYWORD
+  #define EIGEN_RESTRICT
+#endif
+#ifndef EIGEN_RESTRICT
+  #define EIGEN_RESTRICT __restrict
+#endif
+
+#ifndef EIGEN_STACK_ALLOCATION_LIMIT
+// 131072 == 128 KB
+#define EIGEN_STACK_ALLOCATION_LIMIT 131072
+#endif
+
+#ifndef EIGEN_DEFAULT_IO_FORMAT
+#ifdef EIGEN_MAKING_DOCS
+// format used in Eigen's documentation
+// needed to define it here as escaping characters in CMake add_definition's argument seems very problematic.
+#define EIGEN_DEFAULT_IO_FORMAT Eigen::IOFormat(3, 0, " ", "\n", "", "")
+#else
+#define EIGEN_DEFAULT_IO_FORMAT Eigen::IOFormat()
+#endif
+#endif
+
+// just an empty macro !
+#define EIGEN_EMPTY
+
+#if EIGEN_COMP_MSVC_STRICT && (EIGEN_COMP_MSVC < 1900 ||  defined(__CUDACC_VER__)) // for older MSVC versions, as well as 1900 && CUDA 8, using the base operator is sufficient (cf Bugs 1000, 1324)
+  #define EIGEN_INHERIT_ASSIGNMENT_EQUAL_OPERATOR(Derived) \
+    using Base::operator =;
+#elif EIGEN_COMP_CLANG // workaround clang bug (see http://forum.kde.org/viewtopic.php?f=74&t=102653)
+  #define EIGEN_INHERIT_ASSIGNMENT_EQUAL_OPERATOR(Derived) \
+    using Base::operator =; \
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& operator=(const Derived& other) { Base::operator=(other); return *this; } \
+    template <typename OtherDerived> \
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& operator=(const DenseBase<OtherDerived>& other) { Base::operator=(other.derived()); return *this; }
+#else
+  #define EIGEN_INHERIT_ASSIGNMENT_EQUAL_OPERATOR(Derived) \
+    using Base::operator =; \
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& operator=(const Derived& other) \
+    { \
+      Base::operator=(other); \
+      return *this; \
+    }
+#endif
+
+
+/** \internal
+ * \brief Macro to manually inherit assignment operators.
+ * This is necessary, because the implicitly defined assignment operator gets deleted when a custom operator= is defined.
+ */
+#define EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Derived) EIGEN_INHERIT_ASSIGNMENT_EQUAL_OPERATOR(Derived)
+
+/**
+* Just a side note. Commenting within defines works only by documenting
+* behind the object (via '!<'). Comments cannot be multi-line and thus
+* we have these extra long lines. What is confusing doxygen over here is
+* that we use '\' and basically have a bunch of typedefs with their
+* documentation in a single line.
+**/
+
+#define EIGEN_GENERIC_PUBLIC_INTERFACE(Derived) \
+  typedef typename Eigen::internal::traits<Derived>::Scalar Scalar; /*!< \brief Numeric type, e.g. float, double, int or std::complex<float>. */ \
+  typedef typename Eigen::NumTraits<Scalar>::Real RealScalar; /*!< \brief The underlying numeric type for composed scalar types. \details In cases where Scalar is e.g. std::complex<T>, T were corresponding to RealScalar. */ \
+  typedef typename Base::CoeffReturnType CoeffReturnType; /*!< \brief The return type for coefficient access. \details Depending on whether the object allows direct coefficient access (e.g. for a MatrixXd), this type is either 'const Scalar&' or simply 'Scalar' for objects that do not allow direct coefficient access. */ \
+  typedef typename Eigen::internal::ref_selector<Derived>::type Nested; \
+  typedef typename Eigen::internal::traits<Derived>::StorageKind StorageKind; \
+  typedef typename Eigen::internal::traits<Derived>::StorageIndex StorageIndex; \
+  enum CompileTimeTraits \
+      { RowsAtCompileTime = Eigen::internal::traits<Derived>::RowsAtCompileTime, \
+        ColsAtCompileTime = Eigen::internal::traits<Derived>::ColsAtCompileTime, \
+        Flags = Eigen::internal::traits<Derived>::Flags, \
+        SizeAtCompileTime = Base::SizeAtCompileTime, \
+        MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime, \
+        IsVectorAtCompileTime = Base::IsVectorAtCompileTime }; \
+  using Base::derived; \
+  using Base::const_cast_derived;
+
+
+// FIXME Maybe the EIGEN_DENSE_PUBLIC_INTERFACE could be removed as importing PacketScalar is rarely needed
+#define EIGEN_DENSE_PUBLIC_INTERFACE(Derived) \
+  EIGEN_GENERIC_PUBLIC_INTERFACE(Derived) \
+  typedef typename Base::PacketScalar PacketScalar;
+
+
+#define EIGEN_PLAIN_ENUM_MIN(a,b) (((int)a <= (int)b) ? (int)a : (int)b)
+#define EIGEN_PLAIN_ENUM_MAX(a,b) (((int)a >= (int)b) ? (int)a : (int)b)
+
+// EIGEN_SIZE_MIN_PREFER_DYNAMIC gives the min between compile-time sizes. 0 has absolute priority, followed by 1,
+// followed by Dynamic, followed by other finite values. The reason for giving Dynamic the priority over
+// finite values is that min(3, Dynamic) should be Dynamic, since that could be anything between 0 and 3.
+#define EIGEN_SIZE_MIN_PREFER_DYNAMIC(a,b) (((int)a == 0 || (int)b == 0) ? 0 \
+                           : ((int)a == 1 || (int)b == 1) ? 1 \
+                           : ((int)a == Dynamic || (int)b == Dynamic) ? Dynamic \
+                           : ((int)a <= (int)b) ? (int)a : (int)b)
+
+// EIGEN_SIZE_MIN_PREFER_FIXED is a variant of EIGEN_SIZE_MIN_PREFER_DYNAMIC comparing MaxSizes. The difference is that finite values
+// now have priority over Dynamic, so that min(3, Dynamic) gives 3. Indeed, whatever the actual value is
+// (between 0 and 3), it is not more than 3.
+#define EIGEN_SIZE_MIN_PREFER_FIXED(a,b)  (((int)a == 0 || (int)b == 0) ? 0 \
+                           : ((int)a == 1 || (int)b == 1) ? 1 \
+                           : ((int)a == Dynamic && (int)b == Dynamic) ? Dynamic \
+                           : ((int)a == Dynamic) ? (int)b \
+                           : ((int)b == Dynamic) ? (int)a \
+                           : ((int)a <= (int)b) ? (int)a : (int)b)
+
+// see EIGEN_SIZE_MIN_PREFER_DYNAMIC. No need for a separate variant for MaxSizes here.
+#define EIGEN_SIZE_MAX(a,b) (((int)a == Dynamic || (int)b == Dynamic) ? Dynamic \
+                           : ((int)a >= (int)b) ? (int)a : (int)b)
+
+#define EIGEN_LOGICAL_XOR(a,b) (((a) || (b)) && !((a) && (b)))
+
+#define EIGEN_IMPLIES(a,b) (!(a) || (b))
+
+// the expression type of a standard coefficient wise binary operation
+#define EIGEN_CWISE_BINARY_RETURN_TYPE(LHS,RHS,OPNAME) \
+    CwiseBinaryOp< \
+      EIGEN_CAT(EIGEN_CAT(internal::scalar_,OPNAME),_op)< \
+          typename internal::traits<LHS>::Scalar, \
+          typename internal::traits<RHS>::Scalar \
+      >, \
+      const LHS, \
+      const RHS \
+    >
+
+#define EIGEN_MAKE_CWISE_BINARY_OP(METHOD,OPNAME) \
+  template<typename OtherDerived> \
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const EIGEN_CWISE_BINARY_RETURN_TYPE(Derived,OtherDerived,OPNAME) \
+  (METHOD)(const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived> &other) const \
+  { \
+    return EIGEN_CWISE_BINARY_RETURN_TYPE(Derived,OtherDerived,OPNAME)(derived(), other.derived()); \
+  }
+
+#define EIGEN_SCALAR_BINARY_SUPPORTED(OPNAME,TYPEA,TYPEB) \
+  (Eigen::internal::has_ReturnType<Eigen::ScalarBinaryOpTraits<TYPEA,TYPEB,EIGEN_CAT(EIGEN_CAT(Eigen::internal::scalar_,OPNAME),_op)<TYPEA,TYPEB>  > >::value)
+
+#define EIGEN_EXPR_BINARYOP_SCALAR_RETURN_TYPE(EXPR,SCALAR,OPNAME) \
+  CwiseBinaryOp<EIGEN_CAT(EIGEN_CAT(internal::scalar_,OPNAME),_op)<typename internal::traits<EXPR>::Scalar,SCALAR>, const EXPR, \
+                const typename internal::plain_constant_type<EXPR,SCALAR>::type>
+
+#define EIGEN_SCALAR_BINARYOP_EXPR_RETURN_TYPE(SCALAR,EXPR,OPNAME) \
+  CwiseBinaryOp<EIGEN_CAT(EIGEN_CAT(internal::scalar_,OPNAME),_op)<SCALAR,typename internal::traits<EXPR>::Scalar>, \
+                const typename internal::plain_constant_type<EXPR,SCALAR>::type, const EXPR>
+
+// Workaround for MSVC 2010 (see ML thread "patch with compile for for MSVC 2010")
+#if EIGEN_COMP_MSVC_STRICT<=1600
+#define EIGEN_MSVC10_WORKAROUND_BINARYOP_RETURN_TYPE(X) typename internal::enable_if<true,X>::type
+#else
+#define EIGEN_MSVC10_WORKAROUND_BINARYOP_RETURN_TYPE(X) X
+#endif
+
+#define EIGEN_MAKE_SCALAR_BINARY_OP_ONTHERIGHT(METHOD,OPNAME) \
+  template <typename T> EIGEN_DEVICE_FUNC inline \
+  EIGEN_MSVC10_WORKAROUND_BINARYOP_RETURN_TYPE(const EIGEN_EXPR_BINARYOP_SCALAR_RETURN_TYPE(Derived,typename internal::promote_scalar_arg<Scalar EIGEN_COMMA T EIGEN_COMMA EIGEN_SCALAR_BINARY_SUPPORTED(OPNAME,Scalar,T)>::type,OPNAME))\
+  (METHOD)(const T& scalar) const { \
+    typedef typename internal::promote_scalar_arg<Scalar,T,EIGEN_SCALAR_BINARY_SUPPORTED(OPNAME,Scalar,T)>::type PromotedT; \
+    return EIGEN_EXPR_BINARYOP_SCALAR_RETURN_TYPE(Derived,PromotedT,OPNAME)(derived(), \
+           typename internal::plain_constant_type<Derived,PromotedT>::type(derived().rows(), derived().cols(), internal::scalar_constant_op<PromotedT>(scalar))); \
+  }
+
+#define EIGEN_MAKE_SCALAR_BINARY_OP_ONTHELEFT(METHOD,OPNAME) \
+  template <typename T> EIGEN_DEVICE_FUNC inline friend \
+  EIGEN_MSVC10_WORKAROUND_BINARYOP_RETURN_TYPE(const EIGEN_SCALAR_BINARYOP_EXPR_RETURN_TYPE(typename internal::promote_scalar_arg<Scalar EIGEN_COMMA T EIGEN_COMMA EIGEN_SCALAR_BINARY_SUPPORTED(OPNAME,T,Scalar)>::type,Derived,OPNAME)) \
+  (METHOD)(const T& scalar, const StorageBaseType& matrix) { \
+    typedef typename internal::promote_scalar_arg<Scalar,T,EIGEN_SCALAR_BINARY_SUPPORTED(OPNAME,T,Scalar)>::type PromotedT; \
+    return EIGEN_SCALAR_BINARYOP_EXPR_RETURN_TYPE(PromotedT,Derived,OPNAME)( \
+           typename internal::plain_constant_type<Derived,PromotedT>::type(matrix.derived().rows(), matrix.derived().cols(), internal::scalar_constant_op<PromotedT>(scalar)), matrix.derived()); \
+  }
+
+#define EIGEN_MAKE_SCALAR_BINARY_OP(METHOD,OPNAME) \
+  EIGEN_MAKE_SCALAR_BINARY_OP_ONTHELEFT(METHOD,OPNAME) \
+  EIGEN_MAKE_SCALAR_BINARY_OP_ONTHERIGHT(METHOD,OPNAME)
+
+
+#ifdef EIGEN_EXCEPTIONS
+#  define EIGEN_THROW_X(X) throw X
+#  define EIGEN_THROW throw
+#  define EIGEN_TRY try
+#  define EIGEN_CATCH(X) catch (X)
+#else
+#  ifdef __CUDA_ARCH__
+#    define EIGEN_THROW_X(X) asm("trap;")
+#    define EIGEN_THROW asm("trap;")
+#  else
+#    define EIGEN_THROW_X(X) std::abort()
+#    define EIGEN_THROW std::abort()
+#  endif
+#  define EIGEN_TRY if (true)
+#  define EIGEN_CATCH(X) else
+#endif
+
+
+#if EIGEN_HAS_CXX11_NOEXCEPT
+#   define EIGEN_INCLUDE_TYPE_TRAITS
+#   define EIGEN_NOEXCEPT noexcept
+#   define EIGEN_NOEXCEPT_IF(x) noexcept(x)
+#   define EIGEN_NO_THROW noexcept(true)
+#   define EIGEN_EXCEPTION_SPEC(X) noexcept(false)
+#else
+#   define EIGEN_NOEXCEPT
+#   define EIGEN_NOEXCEPT_IF(x)
+#   define EIGEN_NO_THROW throw()
+#   define EIGEN_EXCEPTION_SPEC(X) throw(X)
+#endif
+
+#endif // EIGEN_MACROS_H
diff --git a/tensorflow/contrib/cmake/tf_cc_ops.cmake b/tensorflow/contrib/cmake/tf_cc_ops.cmake
index b53f428..42e7928 100644
--- a/tensorflow/contrib/cmake/tf_cc_ops.cmake
+++ b/tensorflow/contrib/cmake/tf_cc_ops.cmake
@@ -136,11 +136,16 @@ list(REMOVE_ITEM tf_cc_srcs ${tf_cc_test_srcs})
 add_library(tf_cc OBJECT ${tf_cc_srcs})
 add_dependencies(tf_cc tf_cc_framework tf_cc_ops)
 
+if(WIN32)
 set (pywrap_tensorflow_lib "${CMAKE_CURRENT_BINARY_DIR}/${CMAKE_BUILD_TYPE}/pywrap_tensorflow_internal.lib")
+else(WIN32)
+#set (pywrap_tensorflow_lib "${CMAKE_CURRENT_BINARY_DIR}/${CMAKE_BUILD_TYPE}/libpywrap_tensorflow_internal.so")
+set (pywrap_tensorflow_lib "")
+endif(WIN32)
 add_custom_target(tf_extension_ops)
 
 function(AddUserOps)
-  cmake_parse_arguments(_AT "" "" "TARGET;SOURCES;GPUSOURCES;DEPENDS;DISTCOPY" ${ARGN})
+  cmake_parse_arguments(_AT "" "" "TARGET;SOURCES;GPUSOURCES;DEPENDS;DISTCOPY;LIBS;LIBNAME" ${ARGN})
   if (tensorflow_ENABLE_GPU AND _AT_GPUSOURCES)
     # if gpu build is enabled and we have gpu specific code,
     # hint to cmake that this needs to go to nvcc
@@ -149,18 +154,32 @@ function(AddUserOps)
     set_source_files_properties(${gpu_source} PROPERTIES CUDA_SOURCE_PROPERTY_FORMAT OBJ)
     cuda_compile(gpu_lib ${gpu_source})
   endif()
+  if(NOT _AT_LIBNAME)
+    if(WIN32)
+      set(_AT_LIBNAME "${_AT_TARGET}.pyd")
+    else()
+      set(_AT_LIBNAME "${_AT_TARGET}.so")
+    endif()
+  endif()
+  
   # create shared library from source and cuda obj
   add_library(${_AT_TARGET} SHARED ${_AT_SOURCES} ${gpu_lib})
-  target_link_libraries(${_AT_TARGET} ${pywrap_tensorflow_lib})
+  target_link_libraries(${_AT_TARGET} ${_AT_LIBS})
+  if (tensorflow_ENABLE_GPU AND _AT_GPUSOURCES)
+      # some ops call out to cuda directly; need to link libs for the cuda dlls
+      target_link_libraries(${_AT_TARGET} ${CUDA_LIBRARIES})
+  endif()
   if(WIN32)
-    if (tensorflow_ENABLE_GPU AND _AT_GPUSOURCES)
-        # some ops call out to cuda directly; need to link libs for the cuda dlls
-        target_link_libraries(${_AT_TARGET} ${CUDA_LIBRARIES})
-    endif()
+    target_link_libraries(${_AT_TARGET} ${pywrap_tensorflow_lib})
     if (_AT_DISTCOPY)
         add_custom_command(TARGET ${_AT_TARGET} POST_BUILD
             COMMAND ${CMAKE_COMMAND} -E copy $<TARGET_FILE:${_AT_TARGET}> ${_AT_DISTCOPY}/)
     endif()
+  else()
+    if (_AT_DISTCOPY)
+        add_custom_command(TARGET ${_AT_TARGET} POST_BUILD
+            COMMAND ${CMAKE_COMMAND} -E copy $<TARGET_FILE:${_AT_TARGET}> ${_AT_DISTCOPY}/${_AT_LIBNAME})
+    endif()
   endif()
   if (_AT_DEPENDS)
     add_dependencies(${_AT_TARGET} ${_AT_DEPENDS})
@@ -168,9 +187,17 @@ function(AddUserOps)
   # make sure TF_COMPILE_LIBRARY is not defined for this target
   get_target_property(target_compile_flags  ${_AT_TARGET} COMPILE_FLAGS)
   if(target_compile_flags STREQUAL "target_compile_flags-NOTFOUND")
-    set(target_compile_flags "/UTF_COMPILE_LIBRARY")
+    if(WIN32)
+      set(target_compile_flags "/UTF_COMPILE_LIBRARY")
+    else(WIN32)
+      set(target_compile_flags "-UTF_COMPILE_LIBRARY")
+    endif(WIN32)
   else()
-    set(target_compile_flags "${target_compile_flags} /UTF_COMPILE_LIBRARY")
+    if(WIN32)
+      set(target_compile_flags "${target_compile_flags} /UTF_COMPILE_LIBRARY")
+    else(WIN32)
+      set(target_compile_flags "${target_compile_flags} -UTF_COMPILE_LIBRARY")
+    endif(WIN32)
   endif()
   set_target_properties(${_AT_TARGET} PROPERTIES COMPILE_FLAGS ${target_compile_flags})
   add_dependencies(tf_extension_ops ${_AT_TARGET})
diff --git a/tensorflow/contrib/cmake/tf_core_kernels.cmake b/tensorflow/contrib/cmake/tf_core_kernels.cmake
index 57df33c..b24fb0d 100644
--- a/tensorflow/contrib/cmake/tf_core_kernels.cmake
+++ b/tensorflow/contrib/cmake/tf_core_kernels.cmake
@@ -38,7 +38,7 @@ else(tensorflow_BUILD_ALL_KERNELS)
   )
 endif(tensorflow_BUILD_ALL_KERNELS)
 
-if(tensorflow_BUILD_CONTRIB_KERNELS)
+if(tensorflow_BUILD_CONTRIB_KERNELS AND WIN32)
   set(tf_contrib_kernels_srcs
       "${tensorflow_source_dir}/tensorflow/contrib/factorization/kernels/clustering_ops.cc"
       "${tensorflow_source_dir}/tensorflow/contrib/factorization/kernels/masked_matmul_ops.cc"
@@ -94,7 +94,7 @@ if(tensorflow_BUILD_CONTRIB_KERNELS)
       "${tensorflow_source_dir}/tensorflow/contrib/tpu/ops/tpu_sendrecv_ops.cc"
     )
   list(APPEND tf_core_kernels_srcs ${tf_contrib_kernels_srcs})
-endif(tensorflow_BUILD_CONTRIB_KERNELS)
+endif(tensorflow_BUILD_CONTRIB_KERNELS AND WIN32)
 
 if(NOT tensorflow_ENABLE_SSL_SUPPORT)
   # Cloud libraries require boringssl.
@@ -165,21 +165,31 @@ if(WIN32 AND tensorflow_ENABLE_GPU)
     set(target_compile_flags "${target_compile_flags} /UGOOGLE_CUDA")
   endif()
   set_target_properties(tf_core_kernels_cpu_only PROPERTIES COMPILE_FLAGS ${target_compile_flags})
+else()
+  add_library(tf_core_kernels_cpu_only OBJECT "")
 endif(WIN32 AND tensorflow_ENABLE_GPU)
 
 add_library(tf_core_kernels OBJECT ${tf_core_kernels_srcs})
 add_dependencies(tf_core_kernels tf_core_cpu)
 
-if(WIN32)
-  target_compile_options(tf_core_kernels PRIVATE /MP)
-  if (tensorflow_ENABLE_GPU)
-    set_source_files_properties(${tf_core_gpu_kernels_srcs} PROPERTIES CUDA_SOURCE_PROPERTY_FORMAT OBJ)
-    set(tf_core_gpu_kernels_lib tf_core_gpu_kernels)
-    cuda_add_library(${tf_core_gpu_kernels_lib} ${tf_core_gpu_kernels_srcs})
+if (tensorflow_ENABLE_GPU)
+  if(WIN32)
+    target_compile_options(tf_core_kernels PRIVATE /MP)
+  endif()
+  set_source_files_properties(${tf_core_gpu_kernels_srcs} PROPERTIES CUDA_SOURCE_PROPERTY_FORMAT OBJ)
+  set(tf_core_gpu_kernels_lib tf_core_gpu_kernels)
+  cuda_add_library(${tf_core_gpu_kernels_lib} ${tf_core_gpu_kernels_srcs})
+  if (WIN32)
+    set_target_properties(${tf_core_gpu_kernels_lib}
+                          PROPERTIES DEBUG_POSTFIX ""
+                          COMPILE_FLAGS "${TF_REGULAR_CXX_FLAGS}"
+    )
+  else()
     set_target_properties(${tf_core_gpu_kernels_lib}
                           PROPERTIES DEBUG_POSTFIX ""
                           COMPILE_FLAGS "${TF_REGULAR_CXX_FLAGS}"
+                          POSITION_INDEPENDENT_CODE ON
     )
-    add_dependencies(${tf_core_gpu_kernels_lib} tf_core_cpu)
   endif()
+  add_dependencies(${tf_core_gpu_kernels_lib} tf_core_cpu)
 endif()
diff --git a/tensorflow/contrib/cmake/tf_core_ops.cmake b/tensorflow/contrib/cmake/tf_core_ops.cmake
index b350b82..e2434a2 100644
--- a/tensorflow/contrib/cmake/tf_core_ops.cmake
+++ b/tensorflow/contrib/cmake/tf_core_ops.cmake
@@ -71,6 +71,14 @@ file(GLOB_RECURSE tpu_ops_srcs
      "${tensorflow_source_dir}/tensorflow/contrib/tpu/ops/*.cc"
 )
 
+GENERATE_CONTRIB_OP_LIBRARY(batch "${tensorflow_source_dir}/tensorflow/contrib/batching/ops/batch_ops.cc")
+GENERATE_CONTRIB_OP_LIBRARY(boosted_trees_training "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/ops/training_ops.cc")
+GENERATE_CONTRIB_OP_LIBRARY(boosted_trees_stats_accumulator "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/ops/stats_accumulator_ops.cc")
+GENERATE_CONTRIB_OP_LIBRARY(boosted_trees_split_handler "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/ops/split_handler_ops.cc")
+GENERATE_CONTRIB_OP_LIBRARY(boosted_trees_quantile "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/ops/quantile_ops.cc")
+GENERATE_CONTRIB_OP_LIBRARY(boosted_trees_prediction "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/ops/prediction_ops.cc")
+GENERATE_CONTRIB_OP_LIBRARY(boosted_trees_model "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/ops/model_ops.cc")
+GENERATE_CONTRIB_OP_LIBRARY(boosted_trees_ensemble_optimizer "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/ops/ensemble_optimizer_ops.cc")
 GENERATE_CONTRIB_OP_LIBRARY(cudnn_rnn "${tensorflow_source_dir}/tensorflow/contrib/cudnn_rnn/ops/cudnn_rnn_ops.cc")
 GENERATE_CONTRIB_OP_LIBRARY(factorization_clustering "${tensorflow_source_dir}/tensorflow/contrib/factorization/ops/clustering_ops.cc")
 GENERATE_CONTRIB_OP_LIBRARY(factorization_factorization "${tensorflow_source_dir}/tensorflow/contrib/factorization/ops/factorization_ops.cc")
diff --git a/tensorflow/contrib/cmake/tf_python.cmake b/tensorflow/contrib/cmake/tf_python.cmake
index 0024efa..70b32b9 100755
--- a/tensorflow/contrib/cmake/tf_python.cmake
+++ b/tensorflow/contrib/cmake/tf_python.cmake
@@ -124,6 +124,7 @@ file(GLOB_RECURSE tf_protos_python_srcs RELATIVE ${tensorflow_source_dir}
     "${tensorflow_source_dir}/tensorflow/core/*.proto"
     "${tensorflow_source_dir}/tensorflow/core/profiler/*.proto"
     "${tensorflow_source_dir}/tensorflow/python/*.proto"
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/proto/*.proto"
     "${tensorflow_source_dir}/tensorflow/contrib/decision_trees/proto/*.proto"
     "${tensorflow_source_dir}/tensorflow/contrib/session_bundle/*.proto"
     "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/proto/*.proto"
@@ -140,7 +141,10 @@ RELATIVE_PROTOBUF_GENERATE_PYTHON(
 file(GLOB_RECURSE tf_python_protos_cc_srcs RELATIVE ${tensorflow_source_dir}
     "${tensorflow_source_dir}/tensorflow/core/profiler/*.proto"
     "${tensorflow_source_dir}/tensorflow/python/*.proto"
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/proto/*.proto"
+    "${tensorflow_source_dir}/tensorflow/contrib/decision_trees/proto/*.proto"
     "${tensorflow_source_dir}/tensorflow/contrib/session_bundle/*.proto"
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/proto/*.proto"
     "${tensorflow_source_dir}/tensorflow/contrib/tensorboard/*.proto"
     "${tensorflow_source_dir}/tensorflow/contrib/training/*.proto"
 )
@@ -191,10 +195,12 @@ endfunction()
 
 add_python_module("tensorflow")
 add_python_module("tensorflow/core")
+add_python_module("tensorflow/core/debug")
 add_python_module("tensorflow/core/example")
 add_python_module("tensorflow/core/framework")
 add_python_module("tensorflow/core/lib")
 add_python_module("tensorflow/core/lib/core")
+add_python_module("tensorflow/core/profiler")
 add_python_module("tensorflow/core/protobuf")
 add_python_module("tensorflow/core/util")
 add_python_module("tensorflow/examples")
@@ -203,6 +209,7 @@ add_python_module("tensorflow/examples/tutorials/mnist")
 add_python_module("tensorflow/python")
 add_python_module("tensorflow/python/client")
 add_python_module("tensorflow/python/debug")
+add_python_module("tensorflow/python/debug/ops")
 add_python_module("tensorflow/python/debug/cli")
 add_python_module("tensorflow/python/debug/examples")
 add_python_module("tensorflow/python/debug/lib")
@@ -245,6 +252,8 @@ add_python_module("tensorflow/contrib/android/java/org/tensorflow")
 add_python_module("tensorflow/contrib/android/java/org/tensorflow/contrib")
 add_python_module("tensorflow/contrib/android/java/org/tensorflow/contrib/android")
 add_python_module("tensorflow/contrib/android/jni")
+add_python_module("tensorflow/contrib/batching")
+add_python_module("tensorflow/contrib/batching/ops")
 add_python_module("tensorflow/contrib/bayesflow")
 add_python_module("tensorflow/contrib/bayesflow/examples")
 add_python_module("tensorflow/contrib/bayesflow/examples/reinforce_simple")
@@ -253,6 +262,8 @@ add_python_module("tensorflow/contrib/bayesflow/python/kernel_tests")
 add_python_module("tensorflow/contrib/bayesflow/python/ops")
 add_python_module("tensorflow/contrib/boosted_trees")
 add_python_module("tensorflow/contrib/boosted_trees/proto")
+add_python_module("tensorflow/contrib/boosted_trees/python")
+add_python_module("tensorflow/contrib/boosted_trees/python/ops")
 add_python_module("tensorflow/contrib/cloud")
 add_python_module("tensorflow/contrib/cloud/kernels")
 add_python_module("tensorflow/contrib/cloud/ops")
@@ -650,6 +661,26 @@ GENERATE_PYTHON_OP_LIB("user_ops")
 GENERATE_PYTHON_OP_LIB("training_ops"
   DESTINATION ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/python/training/gen_training_ops.py)
 
+GENERATE_PYTHON_OP_LIB("contrib_batch_ops"
+  DESTINATION ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/batching/ops/gen_batch_ops.py)
+GENERATE_PYTHON_OP_LIB("contrib_tpu_ops"
+  DESTINATION ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/tpu/ops/gen_tpu_ops.py)
+GENERATE_PYTHON_OP_LIB("contrib_boosted_trees_training_ops"
+  DESTINATION ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/boosted_trees/python/ops/gen_training_ops.py)
+GENERATE_PYTHON_OP_LIB("contrib_boosted_trees_stats_accumulator_ops"
+  DESTINATION ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/boosted_trees/python/ops/gen_stats_accumulator_ops.py)
+GENERATE_PYTHON_OP_LIB("contrib_boosted_trees_split_handler_ops"
+  DESTINATION ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/boosted_trees/python/ops/gen_split_handler_ops.py)
+GENERATE_PYTHON_OP_LIB("contrib_boosted_trees_quantile_ops"
+  DESTINATION ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/boosted_trees/python/ops/gen_quantile_ops.py)
+GENERATE_PYTHON_OP_LIB("contrib_boosted_trees_prediction_ops"
+  DESTINATION ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/boosted_trees/python/ops/gen_prediction_ops.py)
+GENERATE_PYTHON_OP_LIB("contrib_boosted_trees_model_ops"
+  DESTINATION ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/boosted_trees/python/ops/gen_model_ops.py)
+
+GENERATE_PYTHON_OP_LIB("contrib_boosted_trees_ensemble_optimizer_ops"
+  DESTINATION ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/boosted_trees/python/ops/gen_ensemble_optimizer_ops.py)
+
 GENERATE_PYTHON_OP_LIB("contrib_cudnn_rnn_ops"
   DESTINATION ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/cudnn_rnn/ops/gen_cudnn_rnn_ops.py)
 GENERATE_PYTHON_OP_LIB("contrib_factorization_clustering_ops"
@@ -806,6 +837,14 @@ if(WIN32)
     )
 endif(WIN32)
 
+if(tensorflow_ENABLE_MPI)
+    add_library(tf_core_mpi OBJECT
+        "${tensorflow_source_dir}/tensorflow/contrib/mpi/mpi_utils.cc"
+        "${tensorflow_source_dir}/tensorflow/contrib/mpi/mpi_server_lib.cc"
+        "${tensorflow_source_dir}/tensorflow/contrib/mpi/mpi_rendezvous_mgr.cc"
+    )
+endif()
+
 # pywrap_tensorflow_internal is a shared library containing all of the
 # TensorFlow runtime and the standard ops and kernels. These are installed into
 # tf_python/tensorflow/python/.
@@ -824,6 +863,7 @@ add_library(pywrap_tensorflow_internal SHARED
     $<TARGET_OBJECTS:tf_grappler>
     $<TARGET_OBJECTS:tf_tools_transform_graph_lib>
     $<$<BOOL:${tensorflow_ENABLE_GRPC_SUPPORT}>:$<TARGET_OBJECTS:tf_core_distributed_runtime>>
+    $<$<BOOL:${tensorflow_ENABLE_MPI}>:$<TARGET_OBJECTS:tf_core_mpi>>
     $<TARGET_OBJECTS:tf_core_kernels>
     $<$<BOOL:${tensorflow_ENABLE_GPU}>:$<TARGET_OBJECTS:tf_core_kernels_cpu_only>>
     $<$<BOOL:${tensorflow_ENABLE_GPU}>:$<TARGET_OBJECTS:tf_stream_executor>>
@@ -847,7 +887,7 @@ target_link_libraries(pywrap_tensorflow_internal PRIVATE
     ${PYTHON_LIBRARIES}
 )
 
-if(WIN32)
+# On Linux, too
     # include contrib/rnn as .so
     #
     set(tf_gru_srcs
@@ -883,9 +923,8 @@ if(WIN32)
         GPUSOURCES ${tf_lstm_gpu_srcs}
         DEPENDS pywrap_tensorflow_internal tf_python_ops
         DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/rnn/python/ops/)
-endif(WIN32)
 
-if(WIN32)
+# On Linux, too
     # include contrib/seq2seq as .so
     #
     set(tf_beam_search_srcs
@@ -903,7 +942,767 @@ if(WIN32)
         GPUSOURCES ${tf_beam_search_gpu_srcs}
         DEPENDS pywrap_tensorflow_internal tf_python_ops
         DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/seq2seq/python/ops/)
-endif(WIN32)
+
+#
+# tf_custom_op_library(
+#    name = "python/ops/_tpu_ops.so",
+#    srcs = [
+#        "ops/cross_replica_ops.cc",
+#        "ops/infeed_ops.cc",
+#        "ops/outfeed_ops.cc",
+#        "ops/replication_ops.cc",
+#        "ops/tpu_configuration_ops.cc",
+#        "ops/tpu_sendrecv_ops.cc",
+#    ],
+#)
+
+set(tf_tpu_srcs 
+    "${tensorflow_source_dir}/tensorflow/contrib/tpu/ops/cross_replica_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tpu/ops/infeed_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tpu/ops/outfeed_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tpu/ops/replication_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tpu/ops/tpu_configuration_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tpu/ops/tpu_sendrecv_ops.cc"
+)
+
+AddUserOps(TARGET _tpu_ops
+        SOURCES "${tf_tpu_srcs}"
+        DEPENDS pywrap_tensorflow_internal tf_python_ops
+        DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/tpu/python/ops/)
+
+#tf_custom_op_library(
+#    name = "python/ops/_skip_gram_ops.so",
+#    srcs = [
+#        "kernels/skip_gram_kernels.cc",
+#        "ops/skip_gram_ops.cc",
+#    ],
+#)
+
+set(tf_skip_gram_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/text/kernels/skip_gram_kernels.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/text/ops/skip_gram_ops.cc"
+)
+
+AddUserOps(TARGET _skip_gram_ops
+        SOURCES "${tf_skip_gram_srcs}"
+        DEPENDS pywrap_tensorflow_internal tf_python_ops
+        DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/text/python/ops/)
+
+#        "kernels/best_splits_op.cc",
+#        "kernels/count_extremely_random_stats_op.cc",
+#        "kernels/finished_nodes_op.cc",
+#        "kernels/grow_tree_op.cc",
+#        "kernels/reinterpret_string_to_float_op.cc",
+#        "kernels/sample_inputs_op.cc",
+#        "kernels/scatter_add_ndim_op.cc",
+#        "kernels/tree_predictions_op.cc",
+#        "kernels/update_fertile_slots_op.cc",
+
+add_library(forest_core STATIC
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/tree_utils.cc"
+)
+add_dependencies(forest_core tf_python_ops)
+#
+set(tf_tensor_forest_v2_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/best_splits_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/count_extremely_random_stats_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/finished_nodes_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/grow_tree_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/reinterpret_string_to_float_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/sample_inputs_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/scatter_add_ndim_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/tree_predictions_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/update_fertile_slots_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/ops/tensor_forest_ops.cc"
+)
+
+AddUserOps(TARGET _tensor_forest_ops
+        SOURCES "${tf_tensor_forest_v2_srcs}"
+        DEPENDS pywrap_tensorflow_internal tf_python_ops forest_core
+        DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/tensor_forest/python/ops/
+	LIBS forest_core)
+
+add_library(generic_tree_model_obj STATIC "${CMAKE_CURRENT_BINARY_DIR}/tensorflow/contrib/decision_trees/proto/generic_tree_model.pb.cc")
+add_library(generic_tree_model_extensions_obj STATIC "${CMAKE_CURRENT_BINARY_DIR}/tensorflow/contrib/decision_trees/proto/generic_tree_model_extensions.pb.cc")
+add_library(tensor_forest_params_proto_obj STATIC "${CMAKE_CURRENT_BINARY_DIR}/tensorflow/contrib/tensor_forest/proto/tensor_forest_params.pb.cc")
+add_library(fertile_stats_proto_obj STATIC "${CMAKE_CURRENT_BINARY_DIR}/tensorflow/contrib/tensor_forest/proto/fertile_stats.pb.cc")
+add_library(tensor_forest_protos SHARED
+    "${CMAKE_CURRENT_BINARY_DIR}/tensorflow/contrib/decision_trees/proto/generic_tree_model.pb.cc"
+    "${CMAKE_CURRENT_BINARY_DIR}/tensorflow/contrib/decision_trees/proto/generic_tree_model_extensions.pb.cc"
+    "${CMAKE_CURRENT_BINARY_DIR}/tensorflow/contrib/tensor_forest/proto/tensor_forest_params.pb.cc"
+    "${CMAKE_CURRENT_BINARY_DIR}/tensorflow/contrib/tensor_forest/proto/fertile_stats.pb.cc"
+)
+add_dependencies(tensor_forest_protos tf_python_ops pywrap_tensorflow_internal)
+add_library(v4_input_data STATIC
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/v4/input_data.cc")
+add_dependencies(v4_input_data tf_python_ops pywrap_tensorflow_internal)
+target_link_libraries(v4_input_data
+#    generic_tree_model_obj
+#    generic_tree_model_extensions_obj
+    forest_core
+)
+add_library(v4_params STATIC
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/v4/params.cc")
+add_dependencies(v4_params tf_python_ops pywrap_tensorflow_internal)
+#target_link_libraries(v4_params tensor_forest_params_proto_obj)
+add_library(v4_leaf_model_operators STATIC
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/v4/leaf_model_operators.cc")
+add_dependencies(v4_leaf_model_operators tf_python_ops pywrap_tensorflow_internal)
+target_link_libraries(v4_leaf_model_operators
+#    generic_tree_model_obj
+#    fertile_stats_proto_obj
+#    tensor_forest_params_proto_obj
+    v4_params
+)
+add_library(v4_decision_node_evaluator STATIC
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/v4/decision_node_evaluator.cc")
+add_dependencies(v4_decision_node_evaluator tf_python_ops pywrap_tensorflow_internal)
+target_link_libraries(v4_decision_node_evaluator
+    v4_input_data
+#    generic_tree_model_obj
+#    generic_tree_model_extensions_obj
+)
+add_library(v4_decision_tree_resource STATIC
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/v4/decision-tree-resource.cc")
+add_dependencies(v4_decision_tree_resource tf_python_ops pywrap_tensorflow_internal)
+target_link_libraries(v4_decision_tree_resource
+    v4_input_data
+#    generic_tree_model_obj
+#    fertile_stats_proto_obj
+    v4_leaf_model_operators
+    v4_decision_node_evaluator
+)
+add_library(v4_stat_utils STATIC
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/v4/stat_utils.cc")
+add_dependencies(v4_stat_utils tf_python_ops pywrap_tensorflow_internal)
+#target_link_libraries(v4_stat_utils generic_tree_model_obj fertile_stats_proto_obj)
+add_library(v4_grow_stats STATIC
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/v4/grow_stats.cc")
+add_dependencies(v4_grow_stats tf_python_ops pywrap_tensorflow_internal)
+target_link_libraries(v4_grow_stats 
+    v4_decision_node_evaluator 
+    v4_input_data v4_params
+    v4_stat_utils
+#    generic_tree_model_obj 
+#    forest_core fertile_stats_proto_obj
+#    tensor_forest_params_proto_obj
+)
+add_library(v4_split_collection_operators STATIC
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/v4/split_collection_operators.cc")
+add_dependencies(v4_split_collection_operators tf_python_ops pywrap_tensorflow_internal)
+target_link_libraries(v4_split_collection_operators
+    v4_grow_stats
+    v4_input_data
+    v4_leaf_model_operators
+    v4_params
+    v4_stat_utils
+#    generic_tree_model_obj
+#    generic_tree_model_extensions_obj
+#    forest_core fertile_stats_proto_obj
+#    tensor_forest_params_proto_obj
+)
+add_library(v4_fertile_stats_resource STATIC
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/v4/fertile-stats-resource.cc")
+add_dependencies(v4_fertile_stats_resource tf_python_ops pywrap_tensorflow_internal)
+#target_link_libraries(v4_fertile_stats_resource v4_decision_node_evaluator v4_input_data v4_leaf_model_operators v4_split_collection_operators fertile_stats_proto_obj tensor_forest_params_proto_obj)
+
+set(tf_tensor_forest_model_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/model_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/ops/model_ops.cc"
+)
+
+AddUserOps(TARGET _model_ops
+        SOURCES "${tf_tensor_forest_model_srcs}"
+        DEPENDS pywrap_tensorflow_internal tf_python_ops forest_core
+        DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/tensor_forest/python/ops/
+#        LIBS forest_core generic_tree_model_obj generic_tree_model_extensions_obj tensor_forest_params_proto_obj v4_decision_tree_resource v4_input_data fertile_stats_proto_obj)
+#       LIBS forest_core v4_decision_tree_resource v4_input_data pywrap_tensorflow_internal)
+        LIBS forest_core v4_decision_tree_resource v4_input_data v4_params  tensor_forest_protos
+)
+
+set(tf_tensor_forest_stats_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/kernels/stats_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/ops/stats_ops.cc"
+)
+
+AddUserOps(TARGET _stats_ops
+        SOURCES "${tf_tensor_forest_stats_srcs}"
+        DEPENDS pywrap_tensorflow_internal tf_python_ops forest_core
+        DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/tensor_forest/python/ops/
+#        LIBS forest_core v4_input_data v4_decision_tree_resource  v4_params v4_fertile_stats_resource generic_tree_model_obj)
+#        LIBS forest_core v4_input_data v4_decision_tree_resource  v4_params v4_fertile_stats_resource pywrap_tensorflow_internal
+        LIBS forest_core v4_input_data v4_decision_tree_resource v4_params v4_fertile_stats_resource v4_split_collection_operators v4_leaf_model_operators tensor_forest_protos
+)
+
+#tf_custom_op_library(
+#    name = "python/ops/_training_ops.so",
+#    srcs = [
+#        "core/ops/hard_routing_function_op.cc",
+#        "core/ops/k_feature_gradient_op.cc",
+#        "core/ops/k_feature_routing_function_op.cc",
+#        "core/ops/routing_function_op.cc",
+#        "core/ops/routing_gradient_op.cc",
+#        "core/ops/stochastic_hard_routing_function_op.cc",
+#        "core/ops/stochastic_hard_routing_gradient_op.cc",
+#        "core/ops/unpack_path_op.cc",
+#    ],
+
+set(tf_tensor_forest_hybrid_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/hybrid/core/ops/hard_routing_function_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/hybrid/core/ops/k_feature_gradient_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/hybrid/core/ops/k_feature_routing_function_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/hybrid/core/ops/routing_function_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/hybrid/core/ops/routing_gradient_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/hybrid/core/ops/stochastic_hard_routing_function_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/hybrid/core/ops/stochastic_hard_routing_gradient_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/hybrid/core/ops/unpack_path_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/tensor_forest/hybrid/core/ops/utils.cc"
+)
+
+AddUserOps(TARGET _training_ops
+        SOURCES "${tf_tensor_forest_hybrid_srcs}"
+        DEPENDS pywrap_tensorflow_internal tf_python_ops forest_core
+        DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/tensor_forest/hybrid/python/ops/
+	LIBS forest_core)
+
+# resampler
+#tf_custom_op_library(
+#    name = "python/ops/_resampler_ops.so",
+#    srcs = [
+#        "kernels/resampler_ops.cc",
+#        "kernels/resampler_ops.h",
+#        "ops/resampler_ops.cc",
+#    ],
+#    gpu_srcs = [
+#        "kernels/resampler_ops_gpu.cu.cc",
+#        "kernels/resampler_ops.h",
+#    ],
+#)
+
+set(tf_resampler_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/resampler/kernels/resampler_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/resampler/ops/resampler_ops.cc"
+)
+set(tf_resampler_gpu_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/resampler/kernels/resampler_ops_gpu.cu.cc"
+)
+
+AddUserOps(TARGET _resampler_ops
+    SOURCES "${tf_resampler_srcs}"
+    GPUSOURCES ${tf_resampler_gpu_srcs}
+    DEPENDS pywrap_tensorflow_internal tf_python_ops
+    DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/resampler/python/ops/)
+
+#tf_custom_op_library(
+#    name = "python/ops/_nccl_ops.so",
+#    srcs = [
+#        "kernels/nccl_manager.cc",
+#        "kernels/nccl_manager.h",
+#        "kernels/nccl_ops.cc",
+#        "ops/nccl_ops.cc",
+#    ],
+#)
+
+if(NOT WIN32 AND tensorflow_ENABLE_GPU AND NCCL_LIBRARY)
+    set(tf_nccl_srcs
+        "${tensorflow_source_dir}/tensorflow/contrib/nccl/kernels/nccl_manager.cc"
+        "${tensorflow_source_dir}/tensorflow/contrib/nccl/kernels/nccl_ops.cc"
+        "${tensorflow_source_dir}/tensorflow/contrib/nccl/ops/nccl_ops.cc"
+    )
+    AddUserOps(TARGET _nccl_ops
+        SOURCES "${tf_nccl_srcs}"
+        DEPENDS pywrap_tensorflow_internal tf_python_ops
+        DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/nccl/python/ops/
+        LIBS "${NCCL_LIBRARY}" ${CUDA_LIBRARIES}
+    )
+endif()
+
+# memory_stats
+#tf_custom_op_library(
+#    name = "python/ops/_memory_stats_ops.so",
+#    srcs = [
+#        "kernels/memory_stats_ops.cc",
+#        "ops/memory_stats_ops.cc",
+#    ],
+#)
+
+set(tf_memory_stats_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/memory_stats/kernels/memory_stats_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/memory_stats/ops/memory_stats_ops.cc"
+)
+
+AddUserOps(TARGET _memory_stats_ops
+    SOURCES "${tf_memory_stats_srcs}"
+    DEPENDS pywrap_tensorflow_internal tf_python_ops
+    DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/memory_stats/python/ops/)
+
+# layers
+#tf_custom_op_library(
+#    name = "python/ops/_sparse_feature_cross_op.so",
+#    srcs = [
+#        "ops/sparse_feature_cross_op.cc",
+#    ],
+#    deps = [
+#        "//tensorflow/contrib/layers/kernels:sparse_feature_cross_kernel",
+#    ],
+#)
+
+set(tf_layers_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/layers/ops/sparse_feature_cross_op.cc"
+)
+
+AddUserOps(TARGET _sparse_feature_cross_op
+    SOURCES "${tf_layers_srcs}"
+    DEPENDS pywrap_tensorflow_internal tf_python_ops
+    DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/layers/python/ops/)
+
+# input_pipeline
+#tf_custom_op_library(
+#    name = "python/ops/_input_pipeline_ops.so",
+#    srcs = [
+#        "ops/input_pipeline_ops.cc",
+#    ],
+#)
+
+set(tf_input_pipeline_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/input_pipeline/ops/input_pipeline_ops.cc"
+)
+    
+AddUserOps(TARGET _input_pipeline_ops
+    SOURCES "${tf_input_pipeline_srcs}"
+    DEPENDS pywrap_tensorflow_internal tf_python_ops
+    DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/input_pipeline/python/ops/)
+
+# image
+#tf_custom_op_library(
+#    name = "python/ops/_image_ops.so",
+#    srcs = [
+#        "kernels/bipartite_match_op.cc",
+#        "kernels/image_ops.cc",
+#        "kernels/image_ops.h",
+#        "ops/image_ops.cc",
+#    ],
+#    gpu_srcs = [
+#        "kernels/image_ops_gpu.cu.cc",
+#        "kernels/image_ops.h",
+#    ],
+#)
+set(tf_image_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/image/kernels/bipartite_match_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/image/kernels/image_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/image/ops/image_ops.cc"
+)
+
+set(tf_image_gpu_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/image/kernels/image_ops_gpu.cu.cc"
+)
+
+AddUserOps(TARGET _image_ops
+    SOURCES "${tf_image_srcs}"
+    GPUSOURCES ${tf_image_gpu_srcs}
+    DEPENDS pywrap_tensorflow_internal tf_python_ops
+    DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/image/python/ops/)
+
+#tf_custom_op_library(
+#    name = "python/ops/_single_image_random_dot_stereograms.so",
+#    srcs = [
+#        "kernels/single_image_random_dot_stereograms_ops.cc",
+#        "ops/single_image_random_dot_stereograms_ops.cc",
+#    ],
+#)
+set(tf_single_image_random_dot_stereograms_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/image/kernels/single_image_random_dot_stereograms_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/image/ops/single_image_random_dot_stereograms_ops.cc"
+)
+
+AddUserOps(TARGET _single_image_random_dot_stereograms
+    SOURCES "${tf_single_image_random_dot_stereograms_srcs}"
+    DEPENDS pywrap_tensorflow_internal tf_python_ops
+    DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/image/python/ops/)
+
+# framework
+#tf_custom_op_library(
+#    name = "python/ops/_variable_ops.so",
+#    srcs = [
+#        "kernels/zero_initializer_op.cc",
+#        "kernels/zero_initializer_op.h",
+#        "ops/variable_ops.cc",
+#    ],
+#    gpu_srcs = [
+#        "kernels/zero_initializer_op_gpu.cu.cc",
+#        "kernels/zero_initializer_op.h",
+#    ],
+#)
+
+set(tf_framework_variable_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/framework/kernels/zero_initializer_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/framework/ops/variable_ops.cc"
+)
+
+set(tf_framework_variable_gpu_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/framework/kernels/zero_initializer_op_gpu.cu.cc"
+)
+
+AddUserOps(TARGET _variable_ops
+    SOURCES "${tf_framework_variable_srcs}"
+    GPUSOURCES ${tf_framework_variable_gpu_srcs}
+    DEPENDS pywrap_tensorflow_internal tf_python_ops
+    DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/framework/python/ops/)
+
+#tf_custom_op_library(
+#    name = "python/ops/_checkpoint_ops.so",
+#    srcs = [
+#        "kernels/generate_vocab_remapping_op.cc",
+#        "kernels/load_and_remap_matrix_op.cc",
+#        "ops/checkpoint_ops.cc",
+#    ],
+#    deps = [
+#        "//tensorflow/core/kernels:lookup_headers_lib",
+#        "//tensorflow/core/util/tensor_bundle:tensor_bundle_headers_lib",
+#    ],
+#)
+
+set(tf_framework_checkpoint_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/framework/kernels/generate_vocab_remapping_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/framework/kernels/load_and_remap_matrix_op.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/framework/ops/checkpoint_ops.cc"
+)
+
+AddUserOps(TARGET _checkpoint_ops
+    SOURCES "${tf_framework_checkpoint_srcs}"
+    DEPENDS pywrap_tensorflow_internal tf_python_ops
+    DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/framework/python/ops/)
+
+# factorization
+#tf_custom_op_library(
+#    name = "python/ops/_clustering_ops.so",
+#    srcs = [
+#        "ops/clustering_ops.cc",
+#        "kernels/clustering_ops.cc"
+#    ],
+#)
+
+set(tf_factorization_clustering_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/factorization/kernels/clustering_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/factorization/ops/clustering_ops.cc"
+)
+
+AddUserOps(TARGET _clustering_ops
+    SOURCES "${tf_factorization_clustering_srcs}"
+    DEPENDS pywrap_tensorflow_internal tf_python_ops
+    DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/factorization/python/ops/)
+
+#tf_custom_op_library(
+#    name = "python/ops/_factorization_ops.so",
+#    srcs = [
+#        "ops/factorization_ops.cc",
+#        "kernels/masked_matmul_ops.cc",
+#        "kernels/wals_solver_ops.cc",
+#    ],
+#)
+
+set(tf_factorization_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/factorization/kernels/masked_matmul_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/factorization/kernels/wals_solver_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/factorization/ops/factorization_ops.cc"
+)
+
+AddUserOps(TARGET _factorization_ops
+    SOURCES "${tf_factorization_srcs}"
+    DEPENDS pywrap_tensorflow_internal tf_python_ops
+    DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/factorization/python/ops/)
+
+# cudnn_rnn
+#tf_custom_op_library(
+#    name = "python/ops/_cudnn_rnn_ops.so",
+#    srcs = [
+#        "kernels/cudnn_rnn_ops.cc",
+#        "ops/cudnn_rnn_ops.cc",
+#    ],
+#    deps = [
+#        "//tensorflow/core/kernels:bounds_check_lib",
+#    ],
+#)
+
+if(tensorflow_ENABLE_GPU)
+    set(tf_cudnn_rnn_srcs
+        "${tensorflow_source_dir}/tensorflow/contrib/cudnn_rnn/kernels/cudnn_rnn_ops.cc"
+        "${tensorflow_source_dir}/tensorflow/contrib/cudnn_rnn/ops/cudnn_rnn_ops.cc"
+    )
+
+    AddUserOps(TARGET _cudnn_rnn_ops
+        SOURCES "${tf_cudnn_rnn_srcs}"
+        DEPENDS pywrap_tensorflow_internal tf_python_ops
+        DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/cudnn_rnn/python/ops/
+	LIBS ${CUDA_LIBRARIES})
+endif()
+
+add_library(tf_boosted_trees_learner_proto_obj STATIC "${CMAKE_CURRENT_BINARY_DIR}/tensorflow/contrib/boosted_trees/proto/learner.pb.cc")
+add_dependencies(tf_boosted_trees_learner_proto_obj tf_python_ops pywrap_tensorflow_internal)
+add_library(tf_boosted_trees_quantiles_proto_obj STATIC "${CMAKE_CURRENT_BINARY_DIR}/tensorflow/contrib/boosted_trees/proto/quantiles.pb.cc")
+add_dependencies(tf_boosted_trees_quantiles_proto_obj tf_python_ops pywrap_tensorflow_internal)
+add_library(tf_boosted_trees_split_info_proto_obj STATIC "${CMAKE_CURRENT_BINARY_DIR}/tensorflow/contrib/boosted_trees/proto/split_info.pb.cc")
+add_dependencies(tf_boosted_trees_split_info_proto_obj tf_python_ops pywrap_tensorflow_internal)
+add_library(tf_boosted_trees_tree_config_proto_obj STATIC "${CMAKE_CURRENT_BINARY_DIR}/tensorflow/contrib/boosted_trees/proto/tree_config.pb.cc")
+add_dependencies(tf_boosted_trees_tree_config_proto_obj tf_python_ops pywrap_tensorflow_internal)
+# boosted_trees
+#cc_library(
+#    name = "utils",
+#    srcs = [
+#        "utils/batch_features.cc",
+#        "utils/dropout_utils.cc",
+#        "utils/examples_iterable.cc",
+#        "utils/parallel_for.cc",
+#        "utils/sparse_column_iterable.cc",
+#        "utils/tensor_utils.cc",
+#    ],
+#        "//tensorflow/contrib/boosted_trees/proto:learner_proto_cc",
+#)
+set(tf_boosted_trees_utils_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/lib/utils/batch_features.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/lib/utils/dropout_utils.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/lib/utils/examples_iterable.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/lib/utils/parallel_for.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/lib/utils/sparse_column_iterable.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/lib/utils/tensor_utils.cc"
+)
+add_library(tf_boosted_trees_utils_lib STATIC ${tf_boosted_trees_utils_srcs})
+target_link_libraries(tf_boosted_trees_learner_proto_obj)
+add_dependencies(tf_boosted_trees_utils_lib tf_python_ops)
+
+#tf_custom_op_library(
+#    name = "python/ops/_model_ops.so",
+#    srcs = [
+#        "kernels/model_ops.cc",
+#        "ops/model_ops.cc",
+#    ],
+#    deps = [
+#        "//tensorflow/contrib/boosted_trees/lib:utils",
+#    ],
+#)
+
+set(tf_boosted_trees_model_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/kernels/model_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/ops/model_ops.cc"
+)
+
+AddUserOps(TARGET boosted_trees_model_ops
+    SOURCES "${tf_boosted_trees_model_srcs}"
+    DEPENDS pywrap_tensorflow_internal tf_python_ops
+    DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/boosted_trees/python/ops/
+    LIBS tf_boosted_trees_utils_lib tf_boosted_trees_learner_proto_obj tf_boosted_trees_quantiles_proto_obj tf_boosted_trees_split_info_proto_obj tf_boosted_trees_tree_config_proto_obj
+    LIBNAME "_model_ops.so"
+)
+
+#cc_library(
+#    name = "feature-column-handlers",
+#    srcs = [
+#        "learner/stochastic/handlers/bias-feature-column-handler.cc",
+#        "learner/stochastic/handlers/categorical-feature-column-handler.cc",
+#        "learner/stochastic/handlers/dense-quantized-feature-column-handler.cc",
+#        "learner/stochastic/handlers/sparse-quantized-feature-column-handler.cc",
+#    ],
+#        ":feature-split-candidate",
+#        ":feature-stats-accumulator",
+#)
+set(tf_boosted_trees_feature_column_handlers_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/lib/learner/stochastic/handlers/bias-feature-column-handler.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/lib/learner/stochastic/handlers/categorical-feature-column-handler.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/lib/learner/stochastic/handlers/dense-quantized-feature-column-handler.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/lib/learner/stochastic/handlers/sparse-quantized-feature-column-handler.cc"
+)
+add_library(tf_boosted_trees_feature_column_handlers_lib STATIC ${tf_boosted_trees_utils_srcs})
+target_link_libraries(tf_boosted_trees_feature_column_handlers_lib tf_boosted_trees_learner_proto_obj)
+add_dependencies(tf_boosted_trees_feature_column_handlers_lib tf_python_ops)
+
+#tf_custom_op_library(
+#    name = "python/ops/_split_handler_ops.so",
+#    srcs = [
+#        "kernels/split_handler_ops.cc",
+#        "ops/split_handler_ops.cc",
+#    ],
+#    deps = [
+#        "//tensorflow/contrib/boosted_trees/lib:feature-column-handlers",
+#    ],
+#)
+set(tf_boosted_trees_split_handler_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/kernels/split_handler_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/ops/split_handler_ops.cc"
+)
+
+AddUserOps(TARGET _split_handler_ops
+    SOURCES "${tf_boosted_trees_split_handler_srcs}"
+    DEPENDS pywrap_tensorflow_internal tf_python_ops
+    DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/boosted_trees/python/ops/
+    LIBS tf_boosted_trees_feature_column_handlers_lib tf_boosted_trees_learner_proto_obj tf_boosted_trees_quantiles_proto_obj tf_boosted_trees_split_info_proto_obj tf_boosted_trees_tree_config_proto_obj
+)
+
+#tf_custom_op_library(
+#    name = "python/ops/_training_ops.so",
+#    srcs = [
+#        "kernels/training_ops.cc",
+#        "ops/training_ops.cc",
+#    ],
+#    deps = [
+#        "//tensorflow/contrib/boosted_trees/lib:utils",
+#    ],
+#)
+set(tf_boosted_trees_training_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/kernels/training_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/ops/training_ops.cc"
+)
+
+AddUserOps(TARGET boosted_trees_training_ops
+    SOURCES "${tf_boosted_trees_training_srcs}"
+    DEPENDS pywrap_tensorflow_internal tf_python_ops
+    DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/boosted_trees/python/ops/
+    LIBS tf_boosted_trees_utils_lib tf_boosted_trees_learner_proto_obj tf_boosted_trees_quantiles_proto_obj tf_boosted_trees_split_info_proto_obj tf_boosted_trees_tree_config_proto_obj
+    LIBNAME "_training_ops.so"
+)
+#cc_library(
+#    name = "trees",
+#    srcs = ["trees/decision_tree.cc"],
+#    deps = [
+#        "//tensorflow/contrib/boosted_trees/lib:utils",
+#        "//tensorflow/contrib/boosted_trees/proto:tree_config_proto_cc",
+#    ],
+#)
+add_library(tf_boosted_trees_trees_lib STATIC
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/lib/trees/decision_tree.cc"
+)
+target_link_libraries(tf_boosted_trees_trees_lib tf_boosted_trees_tree_config_proto_obj)
+add_dependencies(tf_boosted_trees_trees_lib tf_python_ops)
+#cc_library(
+#    name = "models",
+#    srcs = ["models/multiple_additive_trees.cc"],
+#    hdrs = ["models/multiple_additive_trees.h"],
+#    deps = [
+#        ":trees",
+#        ":utils",
+#        "//tensorflow/contrib/boosted_trees/proto:tree_config_proto_cc",
+#        "//tensorflow/core:framework_headers_lib",
+#    ],
+#)
+add_library(tf_boosted_trees_models_lib STATIC
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/lib/models/multiple_additive_trees.cc"
+)
+target_link_libraries(tf_boosted_trees_models_lib tf_boosted_trees_tree_config_proto_obj)
+add_dependencies(tf_boosted_trees_models_lib tf_python_ops)
+#cc_library(
+#    name = "example_partitioner",
+#    srcs = ["learner/common/partitioners/example_partitioner.cc"],
+#    deps = [
+#        "//tensorflow/contrib/boosted_trees/lib:trees",
+#        "//tensorflow/contrib/boosted_trees/lib:utils",
+#    ],
+#)
+add_library(tf_boosted_trees_example_partitioner_lib STATIC
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/lib/learner/common/partitioners/example_partitioner.cc"
+)
+add_dependencies(tf_boosted_trees_example_partitioner_lib tf_python_ops)
+#tf_custom_op_library(
+#    name = "python/ops/_prediction_ops.so",
+#    srcs = [
+#        "kernels/prediction_ops.cc",
+#        "ops/prediction_ops.cc",
+#    ],
+#    deps = [
+#        "//tensorflow/contrib/boosted_trees/lib:example_partitioner",
+#        "//tensorflow/contrib/boosted_trees/lib:models",
+#        "//tensorflow/contrib/boosted_trees/lib:utils",
+#    ],
+#)
+set(tf_boosted_trees_prediction_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/kernels/prediction_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/ops/prediction_ops.cc"
+)
+
+AddUserOps(TARGET _prediction_ops
+    SOURCES "${tf_boosted_trees_prediction_srcs}"
+    DEPENDS pywrap_tensorflow_internal tf_python_ops
+    DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/boosted_trees/python/ops/
+    LIBS tf_boosted_trees_utils_lib tf_boosted_trees_models_lib tf_boosted_trees_trees_lib tf_boosted_trees_example_partitioner_lib tf_boosted_trees_learner_proto_obj tf_boosted_trees_quantiles_proto_obj tf_boosted_trees_split_info_proto_obj tf_boosted_trees_tree_config_proto_obj
+)
+#tf_custom_op_library(
+#    name = "python/ops/_quantile_ops.so",
+#    srcs = [
+#        "kernels/quantile_ops.cc",
+#        "ops/quantile_ops.cc",
+#    ],
+#    deps = [
+#        "//tensorflow/contrib/boosted_trees/lib:utils",
+#    ],
+#)
+set(tf_boosted_trees_quantile_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/kernels/quantile_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/ops/quantile_ops.cc"
+)
+AddUserOps(TARGET _quantile_ops
+    SOURCES "${tf_boosted_trees_quantile_srcs}"
+    DEPENDS pywrap_tensorflow_internal tf_python_ops
+    DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/boosted_trees/python/ops/
+    LIBS tf_boosted_trees_utils_lib tf_boosted_trees_learner_proto_obj tf_boosted_trees_quantiles_proto_obj tf_boosted_trees_split_info_proto_obj tf_boosted_trees_tree_config_proto_obj
+)
+#tf_custom_op_library(
+#    name = "python/ops/_ensemble_optimizer_ops.so",
+#    srcs = [
+#        "kernels/ensemble_optimizer_ops.cc",
+#        "ops/ensemble_optimizer_ops.cc",
+#    ],
+#    deps = [
+#        "//tensorflow/contrib/boosted_trees/lib:utils",
+#    ],
+#)
+set(tf_boosted_trees_ensemble_optimizer_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/kernels/ensemble_optimizer_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/ops/ensemble_optimizer_ops.cc"
+)
+AddUserOps(TARGET _ensemble_optimizer_ops
+    SOURCES "${tf_boosted_trees_ensemble_optimizer_srcs}"
+    DEPENDS pywrap_tensorflow_internal tf_python_ops
+    DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/boosted_trees/python/ops/
+    LIBS tf_boosted_trees_utils_lib tf_boosted_trees_learner_proto_obj tf_boosted_trees_quantiles_proto_obj tf_boosted_trees_split_info_proto_obj tf_boosted_trees_tree_config_proto_obj
+)
+#tf_custom_op_library(
+#    name = "python/ops/_stats_accumulator_ops.so",
+#    srcs = [
+#        "kernels/stats_accumulator_ops.cc",
+#        "ops/stats_accumulator_ops.cc",
+#    ],
+#    deps = [
+#        "//tensorflow/contrib/boosted_trees/lib:utils",
+#    ],
+#)
+set(tf_boosted_trees_stats_accumulator_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/kernels/stats_accumulator_ops.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/ops/stats_accumulator_ops.cc"
+)
+AddUserOps(TARGET _stats_accumulator_ops
+    SOURCES "${tf_boosted_trees_stats_accumulator_srcs}"
+    DEPENDS pywrap_tensorflow_internal tf_python_ops
+    DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/boosted_trees/python/ops/
+    LIBS tf_boosted_trees_utils_lib tf_boosted_trees_learner_proto_obj tf_boosted_trees_quantiles_proto_obj tf_boosted_trees_split_info_proto_obj tf_boosted_trees_tree_config_proto_obj
+)
+
+#tf_custom_op_library(
+#    name = "python/ops/_batch_ops.so",
+#    srcs = ["ops/batch_ops.cc"],
+#    deps = [
+#        "//tensorflow/contrib/batching/kernels:batch_kernels",
+#    ],
+#)
+# "//tensorflow/contrib/batching/kernels:batch_kernels",
+# "//tensorflow/contrib/batching/util:periodic_function",
+set(tf_batch_srcs
+    "${tensorflow_source_dir}/tensorflow/contrib/batching/util/periodic_function.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/batching/kernels/batch_kernels.cc"
+    "${tensorflow_source_dir}/tensorflow/contrib/batching/ops/batch_ops.cc"
+)
+AddUserOps(TARGET _batch_ops
+    SOURCES "${tf_batch_srcs}"
+    DEPENDS pywrap_tensorflow_internal tf_python_ops
+    DISTCOPY ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/contrib/batch/python/ops/)
+
 
 ############################################################
 # Build a PIP package containing the TensorFlow runtime.
@@ -936,6 +1735,9 @@ else()
   add_custom_command(TARGET tf_python_build_pip_package POST_BUILD
     COMMAND ${CMAKE_COMMAND} -E copy ${CMAKE_CURRENT_BINARY_DIR}/libpywrap_tensorflow_internal.so
                                      ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/python/_pywrap_tensorflow_internal.so)
+  add_custom_command(TARGET tf_python_build_pip_package POST_BUILD
+    COMMAND ${CMAKE_COMMAND} -E copy ${CMAKE_CURRENT_BINARY_DIR}/libtensor_forest_protos.so
+                                     ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/libtensor_forest_protos.so)
 endif()
 add_custom_command(TARGET tf_python_build_pip_package POST_BUILD
   COMMAND ${CMAKE_COMMAND} -E copy ${tensorflow_source_dir}/tensorflow/tools/pip_package/README
@@ -983,6 +1785,7 @@ add_custom_command(TARGET tf_python_build_pip_package POST_BUILD
   COMMAND ${CMAKE_COMMAND} -E copy_directory ${tensorflow_source_dir}/tensorflow/stream_executor
                                    ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/include/tensorflow/stream_executor)
 
+if(WIN32)
 # google protobuf headers
 add_custom_command(TARGET tf_python_build_pip_package PRE_BUILD
   COMMAND ${CMAKE_COMMAND} -E make_directory
@@ -1031,13 +1834,5 @@ add_custom_command(TARGET tf_python_build_pip_package PRE_BUILD
 add_custom_command(TARGET tf_python_build_pip_package POST_BUILD
   COMMAND ${CMAKE_COMMAND} -E copy_directory ${CMAKE_CURRENT_BINARY_DIR}/eigen/src/eigen/unsupported/Eigen
                                    ${CMAKE_CURRENT_BINARY_DIR}/tf_python/tensorflow/include/unsupported/Eigen)
+endif(WIN32)
 
-if(${tensorflow_ENABLE_GPU})
-  add_custom_command(TARGET tf_python_build_pip_package POST_BUILD
-    COMMAND ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_BINARY_DIR}/tf_python/setup.py bdist_wheel --project_name tensorflow_gpu
-    WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}/tf_python)
-else()
-  add_custom_command(TARGET tf_python_build_pip_package POST_BUILD
-    COMMAND ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_BINARY_DIR}/tf_python/setup.py bdist_wheel
-    WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}/tf_python)
-endif(${tensorflow_ENABLE_GPU})
